@article{Ahrens2022,
  author        = {Kyra Ahrens and Matthias Kerzel and Jae Hee Lee and Cornelius Weber and Stefan Wermter},
  journal       = {IJCAI 2022 Workshop on Spatio-Temporal Reasoning and Learning},
  title         = {Knowing Earlier what Right Means to You: A Comprehensive VQA Dataset for Grounding Relative Directions via Multi-Task Learning},
  year          = {2022},
  month         = jul,
  abstract      = {Spatial reasoning poses a particular challenge for intelligent agents and is at the same time a prerequisite for their successful interaction and communication in the physical world. One such reasoning task is to describe the position of a target object with respect to the intrinsic orientation of some reference object via relative directions. In this paper, we introduce GRiD-A-3D, a novel diagnostic visual question-answering (VQA) dataset based on abstract objects. Our dataset allows for a fine-grained analysis of end-to-end VQA models' capabilities to ground relative directions. At the same time, model training requires considerably fewer computational resources compared with existing datasets, yet yields a comparable or even higher performance. Along with the new dataset, we provide a thorough evaluation based on two widely known end-to-end VQA architectures trained on GRiD-A-3D. We demonstrate that within a few epochs, the subtasks required to reason over relative directions, such as recognizing and locating objects in a scene and estimating their intrinsic orientations, are learned in the order in which relative directions are intuitively processed.},
  archiveprefix = {arXiv},
  doi           = {10.48550/arxiv.2207.02624},
  eprint        = {2207.02624},
  file          = {:papers/Ahrens2022 - Knowing Earlier What Right Means to You_ a Comprehensive VQA Dataset for Grounding Relative Directions Via Multi Task Learning.pdf:PDF},
  groups        = {Project, AI: Cognitive System, MLT Thesis, Grounding, Referring expressions, RE generation},
  keywords      = {cs.CV, cs.CL},
  primaryclass  = {cs.CV}
}

@inproceedings{Antol2015,
  author    = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
  booktitle = {International Conference on Computer Vision (ICCV)},
  title     = {VQA: Visual Question Answering},
  year      = {2015},
  file      = {:papers/Antol2015 - VQA_ Visual Question Answering.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis}
}

@phdthesis{Appelgren2022,
  author   = {Appelgren, Mattias},
  school   = {The University of Edinburgh},
  title    = {Interactive task learning from corrective feedback},
  year     = {2022},
  month    = mar,
  abstract = {In complex teaching scenarios it can be difficult for teachers to exhaustively express all information a learner requires to master a task. However, the teacher, who will have internalised the task's objectives, will be able to identify good and bad actions in specific scenarios and would be able to formulate advice upon observing those scenarios. This thesis focuses on the design, implementation and evaluation of models that enable experts to teach agents through such situated feedback in an Interactive Task Learning (ITL) setting. There is a class of highly natural speech acts which have so far gone largely unexplored in the domain of ITL: how to exploit evidence provided by a teacher when they correct the learning agent by articulating the mistake they just made. The aim of this thesis is to show that such speech acts can be exploited in an ITL to learn a task in a data efficient manner. Further we aim to show that this is made possible by capturing within the learning agent's models the constraints that are imposed by dialogue coherence. A dialogue is coherent if the current utterance relates to a salient part of its dialogue context with a specific coherence relation, such as explanation, contrast, correction, or elaboration. Our model will exploit the semantics of these relations to restrict the set of possible interpretations of the teacher's utterance and how the utterance relates to the objects involved in the action the teacher is giving feedback on. We test our hypothesis on a tower building task where the set of allowed towers is constrained by rules. The agent starts out ignorant of these rules, and perhaps more fundamentally, is also unaware of the domain-level concepts used to define the rules and natural language terms that denote those concepts. We develop an agent which utilises the coherence of the extended dialogue to interpret and disambiguate the teacher's feedback, and utilises this (estimated) interpretation to refine its model of the domain, the mapping from NL descriptions to their denotations, given their observable visual features, and the planning problem being addressed. We extend this model to deal with utterances containing anaphora and to deal with an imperfect teacher: that is, one who occasionally doesn't provide the correct correction in a timely way, and/or who is confident, but wrong, about the learner's ability to identify from her utterance the salient part of the context that it is intended to correct. Finally, we use these ideas to learn the manner in which actions should be performed.},
  doi      = {http://dx.doi.org/10.7488/era/1983},
  file     = {:papers/Appelgren2022 - Interactive Task Learning from Corrective Feedback.pdf:PDF},
  groups   = {AI: Cognitive System, Grounding, MLT Thesis}
}

﻿
@article{Appelgren2020,
  author   = {Appelgren, Mattias and Lascarides, Alex},
  journal  = {Autonomous Agents and Multi-Agent Systems},
  title    = {Interactive task learning via embodied corrective feedback},
  year     = {2020},
  issn     = {1573-7454},
  month    = {Sep},
  number   = {2},
  pages    = {54},
  volume   = {34},
  abstract = {This paper addresses a task in Interactive Task Learning (Laird et al. IEEE Intell Syst 32:6--21, 2017). The agent must learn to build towers which are constrained by rules, and whenever the agent performs an action which violates a rule the teacher provides verbal corrective feedback: e.g. ``No, red blocks should be on blue blocks''. The agent must learn to build rule compliant towers from these corrections and the context in which they were given. The agent is not only ignorant of the rules at the start of the learning process, but it also has a deficient domain model, which lacks the concepts in which the rules are expressed. Therefore an agent that takes advantage of the linguistic evidence must learn the denotations of neologisms and adapt its conceptualisation of the planning domain to incorporate those denotations. We show that by incorporating constraints on interpretation that are imposed by discourse coherence into the models for learning (Hobbs in On the coherence and structure of discourse, Stanford University, Stanford, 1985; Asher et al. in Logics of conversation, Cambridge University Press, Cambridge, 2003), an agent which utilizes linguistic evidence outperforms a strong baseline which does not.},
  day      = {27},
  doi      = {10.1007/s10458-020-09481-8},
  file     = {:papers/Appelgren2020 - Interactive Task Learning Via Embodied Corrective Feedback.pdf:PDF},
  groups   = {MLT Thesis}
}

@mastersthesis{Aruqi2021,
  author = {Aruqi, Ali},
  school = {University of Gothenburg},
  title  = {EMBODIED QUESTION ANSWERING IN ROBOTIC ENVIRONMENT Automatic generation of a synthetic question-answer data-set},
  year   = {2021},
  month  = nov,
  type   = {mathesis},
  file   = {:papers/Aruqi2021 - EMBODIED QUESTION ANSWERING iN ROBOTIC ENVIRONMENT Automatic Generation of a Synthetic Question Answer Data Set.pdf:PDF},
  groups = {MLT Thesis}
}

@article{Baroni2020,
  author        = {Baroni, Marco},
  journal       = {ArXiv preprint},
  title         = {Rat big, cat eaten! Ideas for a useful deep-agent protolanguage},
  year          = {2020},
  month         = mar,
  abstract      = {Deep-agent communities developing their own language-like communication protocol are a hot (or at least warm) topic in AI. Such agents could be very useful in machine-machine and human-machine interaction scenarios long before they have evolved a protocol as complex as human language. Here, I propose a small set of priorities we should focus on, if we want to get as fast as possible to a stage where deep agents speak a useful protolanguage.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2003.11922},
  eprint        = {2003.11922},
  eprinttype    = {arxiv},
  file          = {:papers/Baroni2020 - Rat Big, Cat Eaten! Ideas for a Useful Deep Agent Protolanguage.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{Baroni2022,
  author    = {Baroni, Marco and Dessi, Roberto and Lazaridou, Angeliki},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts},
  title     = {Emergent Language-Based Coordination In Deep Multi-Agent Systems},
  year      = {2022},
  address   = {Abu Dubai, UAE},
  month     = dec,
  pages     = {11--16},
  publisher = {Association for Computational Linguistics},
  abstract  = {Large pre-trained deep networks are the standard building blocks of modern AI applications. This raises fundamental questions about how to control their behaviour and how to make them efficiently interact with each other. Deep net emergent communication tackles these challenges by studying how to induce communication protocols between neural network agents, and how to include humans in the communication loop. Traditionally, this research had focussed on relatively small-scale experiments where two networks had to develop a discrete code from scratch for referential communication. However, with the rise of large pre-trained language models that can work well on many tasks, the emphasis is now shifting on how to let these models interact through a language-like channel to engage in more complex behaviors. By reviewing several representative papers, we will provide an introduction to deep net emergent communication, we will cover various central topics from the present and recent past, as well as discussing current shortcomings and suggest future directions. The presentation is complemented by a hands-on section where participants will implement and analyze two emergent communications setups from the literature. The tutorial should be of interest to researchers wanting to develop more flexible AI systems, but also to cognitive scientists and linguists interested in the evolution of communication systems.},
  file      = {:papers/Baroni2022 - Emergent Language Based Coordination in Deep Multi Agent Systems.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2022.emnlp-tutorials.3}
}

@article{Bartlett2005,
  author   = {Mark Bartlett and Dimitar Kazakov},
  journal  = {Connection Science},
  title    = {The origins of syntax: from navigation to language},
  year     = {2005},
  number   = {3-4},
  pages    = {271-288},
  volume   = {17},
  abstract = {This article suggests that the parser underlying
              human syntax may have originally evolved to assist
              navigation, a claim supported by computational
              simulations as well as evidence from neuroscience and
              psychology. We discuss two independent conjectures
              about the way in which navigation could have
              supported the emergence of this aspect of the human
              language faculty: firstly, by promoting the
              development of a parser; and secondly, by possibly
              providing a topic of discussion to which this parser
              could have been applied with minimum effort. The
              paper summarizes our previously published experiments
              and provides original results in support of the
              evolutionary advantages this type of communication
              can provide, compared with other foraging strategies.
              Another aspect studied in the experiments is the
              combination and range of environmental factors that
              make communication beneficial, focusing on the
              availability and volatility of resources. We suggest
              that the parser evolved for navigation might
              initially have been limited to handling regular
              languages, and describe a mechanism that may have
              created selective pressure for a context-free
              parser.},
  doi      = {10.1080/09540090500282479},
  file     = {:papers/Bartlett2005 - The Origins of Syntax_ from Navigation to Language.pdf:PDF},
  groups   = {MLT Thesis}
}

@inproceedings{Bay2006,
  author    = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
  booktitle = {Computer Vision -- ECCV 2006},
  title     = {SURF: Speeded Up Robust Features},
  year      = {2006},
  address   = {Berlin, Heidelberg},
  editor    = {Leonardis, Ale{\v{s}} and Bischof, Horst and Pinz, Axel},
  pages     = {404--417},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.},
  file      = {:papers/Bay2006 - SURF_ Speeded up Robust Features.pdf:PDF},
  groups    = {MLT Thesis},
  isbn      = {978-3-540-33833-8}
}

@article{Beattie2016,
  author        = {Beattie, Charles and Leibo, Joel Z. and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and Küttler, Heinrich and Lefrancq, Andrew and Green, Simon and Valdés, Víctor and Sadik, Amir and Schrittwieser, Julian and Anderson, Keith and York, Sarah and Cant, Max and Cain, Adam and Bolton, Adrian and Gaffney, Stephen and King, Helen and Hassabis, Demis and Legg, Shane and Petersen, Stig},
  title         = {DeepMind Lab},
  year          = {2016},
  month         = dec,
  abstract      = {DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1612.03801},
  eprint        = {1612.03801},
  file          = {:papers/Beattie2016 - DeepMind Lab.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.AI},
  publisher     = {arXiv}
}

@inproceedings{Bender2020,
  author    = {Bender, Emily M. and Koller, Alexander},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  title     = {Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data},
  year      = {2020},
  address   = {Online},
  month     = jul,
  pages     = {5185--5198},
  publisher = {Association for Computational Linguistics},
  abstract  = {The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {``}understanding{''} language or capturing {``}meaning{''}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {``}Taking Stock of Where We{'}ve Been and Where We{'}re Going{''}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.},
  doi       = {10.18653/v1/2020.acl-main.463},
  file      = {:papers/Bender2020 - Climbing Towards NLU_ on Meaning, Form, and Understanding in the Age of Data.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2020.acl-main.463}
}

@inproceedings{Bender2021,
  author     = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle  = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  title      = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  year       = {2021},
  address    = {New York, NY, USA},
  pages      = {610–623},
  publisher  = {Association for Computing Machinery},
  series     = {FAccT '21},
  abstract   = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  doi        = {10.1145/3442188.3445922},
  file       = {:papers/Bender2021 - On the Dangers of Stochastic Parrots_ Can Language Models Be Too Big_.pdf:PDF},
  groups     = {MLT Thesis},
  isbn       = {9781450383097},
  location   = {Virtual Event, Canada},
  numpages   = {14},
  priority   = {prio2},
  readstatus = {read}
}

@article{Bernardi2016,
  author    = {Bernardi, Raffaella and Cakici, Ruket and Elliott, Desmond and Erdem, Aykut and Erdem, Erkut and Ikizler-Cinbis, Nazli and Keller, Frank and Muscat, Adrian and Plank, Barbara},
  title     = {Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1601.03896},
  file      = {:papers/Bernardi2016 - Automatic Description Generation from Images_ a Survey of Models, Datasets, and Evaluation Measures.pdf:PDF},
  groups    = {AI: Cognitive System, Grounding, MLT Thesis, Referring expressions},
  keywords  = {Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  publisher = {arXiv}
}

@inproceedings{Bisk2020,
  author    = {Bisk, Yonatan and Holtzman, Ari and Thomason, Jesse and Andreas, Jacob and Bengio, Yoshua and Chai, Joyce and Lapata, Mirella and Lazaridou, Angeliki and May, Jonathan and Nisnevich, Aleksandr and Pinto, Nicolas and Turian, Joseph},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  title     = {Experience Grounds Language},
  year      = {2020},
  address   = {Online},
  month     = nov,
  pages     = {8718--8735},
  publisher = {Association for Computational Linguistics},
  abstract  = {Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful. Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.},
  doi       = {10.18653/v1/2020.emnlp-main.703},
  file      = {:papers/Bisk2020 - Experience Grounds Language.pdf:PDF},
  groups    = {MLT Thesis, Grounding},
  url       = {https://aclanthology.org/2020.emnlp-main.703}
}

@article{Bouchacourt2018,
  author        = {Bouchacourt, Diane and Baroni, Marco},
  title         = {How agents see things: On visual representations in an emergent language game},
  year          = {2018},
  month         = aug,
  abstract      = {There is growing interest in the language developed by agents interacting in emergent-communication settings. Earlier studies have focused on the agents' symbol usage, rather than on their representation of visual input. In this paper, we consider the referential games of Lazaridou et al. (2017) and investigate the representations the agents develop during their evolving interaction. We find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images. We conclude that, if we are interested in developing language-like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1808.10696},
  eprint        = {1808.10696},
  file          = {:papers/Bouchacourt2018 - How Agents See Things_ on Visual Representations in an Emergent Language Game.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv}
}

@article{Bouchacourt2019,
  author        = {Bouchacourt, Diane and Baroni, Marco},
  title         = {Miss Tools and Mr Fruit: Emergent communication in agents learning about object affordances},
  year          = {2019},
  month         = may,
  abstract      = {Recent research studies communication emergence in communities of deep network agents assigned a joint task, hoping to gain insights on human language evolution. We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants. By conducting a thorough pragmatic and semantic analysis of the emergent protocol, we show that the agents solve the shared task through genuine bilateral, referential communication. However, the agents develop multiple idiolects, which makes us conclude that full symmetry is not a sufficient condition for a common language to emerge.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.11871},
  eprint        = {1905.11871},
  file          = {:papers/Bouchacourt2019 - Miss Tools and Mr Fruit_ Emergent Communication in Agents Learning about Object Affordances.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Brown2020,
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal       = {Advances in neural information processing systems},
  title         = {Language Models are Few-Shot Learners},
  year          = {2020},
  pages         = {1877-1901},
  volume        = {33},
  archiveprefix = {arXiv},
  doi           = {10.48550/arxiv.2005.14165},
  eprint        = {2005.14165},
  file          = {:papers/Brown2020 - Language Models Are Few Shot Learners.pdf:PDF},
  groups        = {MLT Thesis},
  primaryclass  = {cs.CL}
}

@mastersthesis{CanoSantin2019,
  author = {Cano Santín, José Miguel},
  school = {University of Gothenburg},
  title  = {Fast visual grounding in interaction},
  year   = {2019},
  month  = oct,
  type   = {mathesis},
  file   = {:papers/CanoSantin2019 - Fast Visual Grounding in Interaction.pdf:PDF},
  groups = {MLT Thesis}
}

@inproceedings{CanoSantin2020,
  author    = {Cano Sant{\'\i}n, Jos{\'e} Miguel and Dobnik, Simon and Ghanimifard, Mehdi},
  booktitle = {Proceedings of the Probability and Meaning Conference (PaM 2020)},
  title     = {Fast visual grounding in interaction: bringing few-shot learning with neural networks to an interactive robot},
  year      = {2020},
  address   = {Gothenburg},
  month     = jun,
  pages     = {53--61},
  publisher = {Association for Computational Linguistics},
  abstract  = {The major shortcomings of using neural networks with situated agents are that in incremental interaction very few learning examples are available and that their visual sensory representations are quite different from image caption datasets. In this work we adapt and evaluate a few-shot learning approach, Matching Networks (Vinyals et al., 2016), to conversational strategies of a robot interacting with a human tutor in order to efficiently learn to categorise objects that are presented to it and also investigate to what degree transfer learning from pre-trained models on images from different contexts can improve its performance. We discuss the implications of such learning on the nature of semantic representations the system has learned.},
  file      = {:papers/CanoSantin2020 - Fast Visual Grounding in Interaction_ Bringing Few Shot Learning with Neural Networks to an Interactive Robot.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2020.pam-1.7}
}

@inproceedings{Cao2018,
  author     = {Kris Cao and Angeliki Lazaridou and Marc Lanctot and Joel Z Leibo and Karl Tuyls and Stephen Clark},
  booktitle  = {International Conference on Learning Representations},
  title      = {Emergent Communication through Negotiation},
  year       = {2018},
  file       = {:papers/Cao2018 - Emergent Communication through Negotiation.pdf:PDF},
  groups     = {MLT Thesis},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://openreview.net/forum?id=Hk6WhagRW}
}

@article{Chaabouni2021,
  author     = {Rahma Chaabouni and Eugene Kharitonov and Emmanuel Dupoux and Marco Baroni},
  journal    = {Proceedings of the National Academy of Sciences},
  title      = {Communicating artificial neural networks develop efficient color-naming systems},
  year       = {2021},
  month      = {mar},
  number     = {12},
  volume     = {118},
  doi        = {10.1073/pnas.2016569118},
  file       = {:papers/Chaabouni2021 - Communicating Artificial Neural Networks Develop Efficient Color Naming Systems.pdf:PDF},
  groups     = {MLT Thesis},
  priority   = {prio2},
  publisher  = {Proceedings of the National Academy of Sciences},
  readstatus = {read}
}

@article{Chaabouni2020,
  author        = {Chaabouni, Rahma and Kharitonov, Eugene and Bouchacourt, Diane and Dupoux, Emmanuel and Baroni, Marco},
  title         = {Compositionality and Generalization in Emergent Languages},
  year          = {2020},
  month         = apr,
  abstract      = {Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as \emph{compositionality}. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results. First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2004.09124},
  eprint        = {2004.09124},
  file          = {:papers/Chaabouni2020 - Compositionality and Generalization in Emergent Languages.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Chaabouni2019,
  author        = {Chaabouni, Rahma and Kharitonov, Eugene and Dupoux, Emmanuel and Baroni, Marco},
  journal       = {Advances in Neural Information Processing Systems},
  title         = {Anti-efficient encoding in emergent communication},
  year          = {2019},
  month         = may,
  volume        = {32},
  abstract      = {Despite renewed interest in emergent language simulations with neural networks, little is known about the basic properties of the induced code, and how they compare to human language. One fundamental characteristic of the latter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words are efficiently associated to shorter strings. We study whether the same pattern emerges when two neural networks, a "speaker" and a "listener", are trained to play a signaling game. Surprisingly, we find that networks develop an \emph{anti-efficient} encoding scheme, in which the most frequent inputs are associated to the longest messages, and messages in general are skewed towards the maximum length threshold. This anti-efficient code appears easier to discriminate for the listener, and, unlike in human communication, the speaker does not impose a contrasting least-effort pressure towards brevity. Indeed, when the cost function includes a penalty for longer messages, the resulting message distribution starts respecting ZLA. Our analysis stresses the importance of studying the basic features of emergent communication in a highly controlled setup, to ensure the latter will not strand too far from human language. Moreover, we present a concrete illustration of how different functional pressures can lead to successful communication codes that lack basic properties of human language, thus highlighting the role such pressures play in the latter.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.12561},
  eprint        = {1905.12561},
  file          = {:papers/Chaabouni2019 - Anti Efficient Encoding in Emergent Communication.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv}
}

@inproceedings{Chaabouni2022,
  author    = {Rahma Chaabouni and Florian Strub and Florent Altch{\'e} and Eugene Tarassov and Corentin Tallec and Elnaz Davoodi and Kory Wallace Mathewson and Olivier Tieleman and Angeliki Lazaridou and Bilal Piot},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergent Communication at Scale},
  year      = {2022},
  file      = {:papers/Chaabouni2022 - Emergent Communication at Scale.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://openreview.net/forum?id=AUGBfDIV9rL}
}

@book{Clark1996,
  author    = {Clark, Herbert H.},
  publisher = {Cambridge University Press},
  title     = {Using language},
  year      = {1996},
  address   = {Cambridge},
  file      = {:papers/Clark1996 - Using Language.pdf:PDF},
  groups    = {MLT Thesis, Referring expressions, Grounding}
}

@article{Clark1986,
  author   = {Herbert H. Clark and Deanna Wilkes-Gibbs},
  journal  = {Cognition},
  title    = {Referring as a collaborative process},
  year     = {1986},
  issn     = {0010-0277},
  number   = {1},
  pages    = {1-39},
  volume   = {22},
  abstract = {In conversation, speakers and addressees work together in the making of a definite reference. In the model we propose, the speaker initiates the process by presenting or inviting a noun phrase. Before going on to the next contribution, the participants, if necessary, repair, expand on, or replace the noun phrase in an iterative process until they reach a version they mutually accept. In doing so they try to minimize their joint effort. The preferred procedure is for the speaker to present a simple noun phrase and for the addressee to accept it by allowing the next contribution to begin. We describe a communication task in which pairs of people conversed about arranging complex figures and show how the proposed model accounts for many features of the references they produced. The model follows, we suggest, from the mutual responsibility that participants in conversation bear toward the understanding of each utterance.
              Résumé
              Au cours d' une conversation, les interlocuteurs travaillent ensemble pour construire une référence définie. Dans le modèle proposè, le locuteur initie le processus en présentant un syntagme nominal. Avant de passer à la contribution suivante, les participants, si cela est nécessaire, corrigent, développent ou remplacent ce syntagme nominal au cours d'un processus itératif jusqu'a ce que soit atteinte une version que tout deux acceptent. En faisant cela ils essaient de minimiser l'effort conjoint. La procedure préférée consiste pour le locuteur à présenter un syntagme nominal simple et pour l'allocuteur d'accepter ce syntagme en donnant le feu vert pour l'échange suivant. Nous décrivons une tache de communication an cours de laquelle deux personnes discutent l'agencement de figures complexes et nous montrons comment le modele proposé rend compte de nombreux traits des références produites. Le modéle découle, selon notre suggestion, de la responsabilité mutuelle que les participants prennent pour que soit compris chaque énoncé durant la conversation.},
  doi      = {10.1016/0010-0277(86)90010-7},
  file     = {:papers/Clark1986 - Referring As a Collaborative Process.pdf:PDF},
  groups   = {MLT Thesis, Referring expressions, Grounding},
  url      = {https://www.sciencedirect.com/science/article/pii/0010027786900107}
}

@book{Cooper2023,
  author    = {Cooper, Robin},
  publisher = {Oxford University Press Press},
  title     = {From Perception to Communication: A Theory of Types for Action and Meaning},
  year      = {2023},
  month     = {June 13},
  series    = {Oxford Studies in Semantics and Pragmatics},
  volume    = {16},
  annote    = {This is an open access title available under the terms of a CC BY-NC-ND 4.0 International licence. It is free to read at Oxford Scholarship Online and offered as a free PDF download from OUP and selected open access locations. This book characterizes a notion of type that covers both linguistic and non-linguistic action, and lays the foundations for a theory of action based on a Theory of Types with Records (TTR). Robin Cooper argues that a theory of language based on action allows the adoption of a perspective on linguistic content that is centred on interaction in dialogue; this approach is crucially different to the traditional view of natural languages as essentially similar to formal languages such as logics developed by philosophers or mathematicians. At the same time, he claims that the substantial technical advantages made by the formal language view of semantics can be incorporated into the action-based view, and that this can lead to important improvements in both intuitive understanding and empirical coverage. This enterprise uses types rather than possible worlds as commonly employed in studies of the semantics of natural language. Types are more tractable than possible worlds and offer greater potential for understanding the implementation of semantics both on machines and in biological brains.},
  file      = {:papers/Cooper2023 - From Perception to Communication_ a Theory of Types for Action and Meaning.pdf:PDF},
  groups    = {MLT Thesis,}
}

@incollection{Coventry2005,
  author     = {Kenny R. Coventry and Angelo Cangelosi and Rohanna Rajapakse and Alison Bacon and Stephen Newstead and Dan Joyce and Lynn V. Richards},
  booktitle  = {Spatial Cognition {IV}. Reasoning, Action, Interaction},
  publisher  = {Springer Berlin Heidelberg},
  title      = {Spatial Prepositions and Vague Quantifiers: Implementing the Functional Geometric Framework},
  year       = {2005},
  pages      = {98--110},
  doi        = {10.1007/978-3-540-32255-9_6},
  file       = {:papers/Coventry2005 - Spatial Prepositions and Vague Quantifiers_ Implementing the Functional Geometric Framework.pdf:PDF},
  groups     = {AI: Cognitive System, RE generation, MLT Thesis},
  readstatus = {read}
}

@article{Dale1995,
  author    = {Dale, Robert and Reiter, Ehud},
  journal   = {Cognitive science},
  title     = {Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions},
  year      = {1995},
  number    = {2},
  pages     = {233--263},
  volume    = {19},
  doi       = {10.48550/ARXIV.CMP-LG/9504020},
  file      = {:papers/Dale1995 - Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions.pdf:PDF},
  groups    = {AI: Cognitive System, MLT Thesis, Referring expressions, Grounding},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences},
  publisher = {Elsevier}
}

@article{Dasgupta2023,
  author  = {Ishita Dasgupta and Christine Kaeser-Chen and Kenneth Marino and Arun Ahuja and Sheila Babayan and Felix Hill and Rob Fergus},
  journal = {ArXiv},
  title   = {Collaborating with language models for embodied reasoning},
  year    = {2023},
  volume  = {abs/2302.00763},
  file    = {:papers/Dasgupta2023 - Collaborating with Language Models for Embodied Reasoning.pdf:PDF},
  groups  = {MLT Thesis},
  url     = {https://api.semanticscholar.org/CorpusID:253180684}
}

@mastersthesis{Graaf2020,
  author     = {de Graaf, Erik},
  school     = {University of Gothenburg},
  title      = {Kille: Learning Objects and Spatial Relations with Kinect},
  year       = {2020},
  month      = aug,
  type       = {mathesis},
  file       = {:papers/Graaf2020 - Kille_ Learning Objects and Spatial Relations with Kinect.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@inproceedings{Deng2009,
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title     = {ImageNet: A large-scale hierarchical image database},
  year      = {2009},
  pages     = {248-255},
  doi       = {10.1109/CVPR.2009.5206848},
  file      = {:papers/Deng2009 - ImageNet_ a Large Scale Hierarchical Image Database.pdf:PDF},
  groups    = {MLT Thesis}
}

@article{Dessi2021,
  author        = {Dessì, Roberto and Kharitonov, Eugene and Baroni, Marco},
  title         = {Interpretable agent communication from scratch (with a generic visual processor emerging on the side)},
  year          = {2021},
  month         = jun,
  abstract      = {As deep networks begin to be deployed as autonomous agents, the issue of how they can communicate with each other becomes important. Here, we train two deep nets from scratch to perform realistic referent identification through unsupervised emergent communication. We show that the largely interpretable emergent protocol allows the nets to successfully communicate even about object types they did not see at training time. The visual representations induced as a by-product of our training regime, moreover, show comparable quality, when re-used as generic visual features, to a recent self-supervised learning model. Our results provide concrete evidence of the viability of (interpretable) emergent deep net communication in a more realistic scenario than previously considered, as well as establishing an intriguing link between this field and self-supervised visual learning.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2106.04258},
  eprint        = {2106.04258},
  file          = {:papers/Dessi2021 - Interpretable Agent Communication from Scratch (with a Generic Visual Processor Emerging on the Side).pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{DeVault2015,
  author     = {David DeVault and Johnathan Mell and J. Gratch},
  booktitle  = {AAAI Spring Symposia},
  title      = {Toward Natural Turn-Taking in a Virtual Human Negotiation Agent},
  year       = {2015},
  file       = {:papers/DeVault2015 - Toward Natural Turn Taking in a Virtual Human Negotiation Agent.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@inproceedings{Devlin2019,
  author     = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle  = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  title      = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year       = {2019},
  address    = {Minneapolis, Minnesota},
  month      = jun,
  pages      = {4171--4186},
  publisher  = {Association for Computational Linguistics},
  abstract   = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  doi        = {10.18653/v1/N19-1423},
  file       = {:papers/Devlin2019 - BERT_ Pre Training of Deep Bidirectional Transformers for Language Understanding.pdf:PDF},
  groups     = {MLT Thesis},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://aclanthology.org/N19-1423}
}

@inproceedings{Dobnik2017,
  author     = {Simon Dobnik and Amelie Åstbom},
  booktitle  = {Proceedings of Saardial: The 21st Workshop on the Semantics and Pragmatics of Dialogue},
  title      = {(Perceptual) grounding as interaction},
  year       = {2017},
  address    = {Saarbrücken},
  editor     = {Volha Petukhova and Ye Tian},
  month      = aug,
  pages      = {17-26},
  publisher  = {SemDial},
  file       = {:papers/Dobnik2017 - (Perceptual) Grounding As Interaction.pdf:PDF},
  groups     = {MLT Thesis, Grounding},
  readstatus = {read}
}

@inproceedings{Dobnik2017a,
  author     = {Simon Dobnik and Erik Wouter de Graaf},
  booktitle  = {Linköping Electronic Conference Proceedings},
  title      = {KILLE: a Framework for Situated Agents for Learning Language Through Interaction},
  year       = {2017},
  address    = {Linköpings universitet},
  publisher  = {Linköping University Electronic Press},
  file       = {:papers/Dobnik2017a - KILLE_ a Framework for Situated Agents for Learning Language through Interaction.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {read}
}

@inproceedings{Dobnik2017b,
  author     = {Simon Dobnik and Erik Wouter de Graaf},
  booktitle  = {CEUR Workshop Proceedings},
  title      = {KILLE: learning grounded language through interaction},
  year       = {2017},
  address    = {Toulouse},
  month      = jul,
  publisher  = {CEUR},
  file       = {:papers/Dobnik2017b - KILLE_ Learning Grounded Language through Interaction.pdf:PDF},
  groups     = {MLT Thesis, Grounding},
  readstatus = {skimmed}
}

@inproceedings{Dobnik2013,
  author     = {Dobnik, Simon and Kelleher, John D.},
  booktitle  = {Proceedings of PRE-CogSci 2013 Production of referring expressions -- bridging the gap between cognitive and computational approaches to reference at CogSci},
  title      = {Towards an automatic identification of functional and geometric spatial prepositions},
  year       = {2013},
  address    = {Berlin, Germany},
  month      = {31 July},
  pages      = {1--6},
  file       = {:papers/Dobnik2013 - Towards an Automatic Identification of Functional and Geometric Spatial Prepositions.pdf:PDF},
  groups     = {Project, AI: Cognitive System, MLT Thesis, Referring expressions, Grounding, RE generation},
  priority   = {prio3},
  readstatus = {read},
  url        = {https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fpre2013.uvt.nl%2Fpdf%2Fdobnik-kelleher.pdf&data=05%7C01%7C%7C84d038df55584d2b11b608dadea1d8b4%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C638067083956924323%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=OwxWkerv8%2BVRu8t7sYZ5FZFsJX3Sy4Ad5LVi7h2sB3Y%3D&reserved=0}
}

@inproceedings{Dobnik2021,
  author    = {Dobnik, Simon and Silfversparre, Vera},
  booktitle = {Proceedings of the 25th Workshop on the Semantics and Pragmatics of Dialogue - Full Papers},
  title     = {The red cup on the left: Reference, coreference and attention in visual dialogue},
  year      = {2021},
  address   = {Potsdam, Germany},
  month     = sep,
  publisher = {SEMDIAL},
  file      = {:papers/Dobnik2021 - The Red Cup on the Left_ Reference, Coreference and Attention in Visual Dialogue.pdf:PDF},
  groups    = {MLT Thesis, Referring expressions, RE resolution, Grounding, RE generation},
  url       = {http://semdial.org/anthology/Z21-Dobnik_semdial_0008.pdf}
}

@inproceedings{Dobnik2018a,
  author    = {Simon Dobnik and Axel Storckenfeldt},
  booktitle = {Proceedings of AixDial - Semdial 2018: The 22st Workshop on the Semantics and Pragmatics of Dialogue},
  title     = {Categorisation of conversational games in free dialogue over spatial scenes},
  year      = {2018},
  address   = {Aix-en-Provence},
  editor    = {Laurent Prévot and Magalie Ochs and Benoît Favre},
  month     = nov,
  publisher = {Semdial},
  file      = {:papers/Dobnik2018a - Categorisation of Conversational Games in Free Dialogue Over Spatial Scenes.pdf:PDF},
  groups    = {MLT Thesis, Grounding, Referring expressions}
}

@mastersthesis{Emampoor2022,
  author = {Emampoor, Yasmeen},
  school = {University of Gothenburg},
  title  = {There is a Microwave in the Hallway},
  year   = {2022},
  month  = apr,
  type   = {mathesis},
  file   = {:papers/Emampoor2022 - There Is a Microwave in the Hallway.pdf:PDF},
  groups = {MLT Thesis}
}

@inproceedings{Evtimova2018,
  author    = {Katrina Evtimova and Andrew Drozdov and Douwe Kiela and Kyunghyun Cho},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergent Communication in a Multi-Modal, Multi-Step Referential Game},
  year      = {2018},
  file      = {:papers/Evtimova2018 - Emergent Communication in a Multi Modal, Multi Step Referential Game.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://openreview.net/forum?id=rJGZq6g0-}
}

@inproceedings{Field2021,
  author    = {Field, Anjalie and Blodgett, Su Lin and Waseem, Zeerak and Tsvetkov, Yulia},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  title     = {A Survey of Race, Racism, and Anti-Racism in {NLP}},
  year      = {2021},
  address   = {Online},
  month     = aug,
  pages     = {1905--1925},
  publisher = {Association for Computational Linguistics},
  abstract  = {Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed single-dimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.},
  doi       = {10.18653/v1/2021.acl-long.149},
  file      = {:papers/Field2021 - A Survey of Race, Racism, and Anti Racism in NLP.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2021.acl-long.149}
}

@misc{Foerster2016,
  author        = {Jakob N. Foerster and Yannis M. Assael and Nando de Freitas and Shimon Whiteson},
  title         = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
  year          = {2016},
  archiveprefix = {arXiv},
  doi           = {10.48550/arxiv.1605.06676},
  eprint        = {1605.06676},
  file          = {:papers/Foerster2016 - Learning to Communicate with Deep Multi Agent Reinforcement Learning.pdf:PDF},
  groups        = {MLT Thesis},
  primaryclass  = {cs.AI}
}

@inproceedings{Ghanimifard2019,
  author    = {Mehdi Ghanimifard and Simon Dobnik},
  booktitle = {Proceedings of the 12th International Conference on Natural Language Generation},
  title     = {What goes into a word: generating image descriptions with top-down spatial knowledge},
  year      = {2019},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/w19-8668},
  file      = {:papers/Ghanimifard2019 - What Goes into a Word_ Generating Image Descriptions with Top down Spatial Knowledge.pdf:PDF},
  groups    = {AI: Cognitive System, Project, MLT Thesis, Referring expressions, Grounding, RE generation}
}

@inproceedings{Ghanimifard2017,
  author     = {Mehdi Ghanimifard and Simon Dobnik},
  booktitle  = {Proceedings of the 12th International Conference on Computational Semantics ({IWCS}) {---} Long papers},
  title      = {Learning to Compose Spatial Relations with Grounded Neural Language Models},
  year       = {2017},
  editor     = {Gardent, Claire and Retor{\'e}, Christian},
  file       = {:papers/Ghanimifard2017 - Learning to Compose Spatial Relations with Grounded Neural Language Models.pdf:PDF},
  groups     = {AI: Cognitive System, MLT Thesis, Grounding, Referring expressions, RE generation},
  journal    = {Proceedings of the 12th International Conference on Computational Semantics ({IWCS}) {---} Long papers},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://aclanthology.org/W17-6808}
}

@inproceedings{Gupta2020,
  author        = {Gupta, Abhinav and Resnick, Cinjon and Foerster, Jakob and Dai, Andrew and Cho, Kyunghyun},
  booktitle     = {Proceedings of the 5th Workshop on Representation Learning for NLP},
  title         = {Compositionality and Capacity in Emergent Languages},
  year          = {2020},
  month         = jul,
  pages         = {34--38},
  publisher     = {Association for Computational Linguistics},
  abstract      = {Many recent works have discussed the propensity, or lack thereof, for emergent languages to exhibit properties of natural languages. A favorite in the literature is learning compositionality. We note that most of those works have focused on communicative bandwidth as being of primary importance. While important, it is not the only contributing factor. In this paper, we investigate the learning biases that affect the efficacy and compositionality of emergent languages. Our foremost contribution is to explore how capacity of a neural network impacts its ability to learn a compositional language. We additionally introduce a set of evaluation metrics with which we analyze the learned languages. Our hypothesis is that there should be a specific range of model capacity and channel bandwidth that induces compositional structure in the resulting language and consequently encourages systematic generalization. While we empirically see evidence for the bottom of this range, we curiously do not find evidence for the top part of the range and believe that this is an open question for the community.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1910.11424},
  eprint        = {1910.11424},
  file          = {:papers/Gupta2020 - Compositionality and Capacity in Emergent Languages.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), Machine Learning (stat.ML), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  readstatus    = {read}
}

@article{Harnad1990,
  author        = {Stevan Harnad},
  journal       = {Physica D 42: 335-346},
  title         = {The Symbol Grounding Problem},
  year          = {1990},
  month         = jun,
  abstract      = {How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) "iconic representations," which are analogs of the proximal sensory projections of distal objects and events, and (2) "categorical representations," which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) "symbolic representations," grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., "An X is a Y that is Z").},
  archiveprefix = {arXiv},
  doi           = {10.1016/0167-2789(90)90087-6},
  eprint        = {cs/9906002},
  file          = {:papers/Harnad1999 - The Symbol Grounding Problem.pdf:PDF},
  groups        = {AI: Cognitive System, MLT Thesis, Grounding},
  keywords      = {cs.AI, I.2.0},
  primaryclass  = {cs.AI},
  readstatus    = {read}
}

@inproceedings{Harris1988,
  author    = {Christopher G. Harris and M. J. Stephens},
  booktitle = {Alvey Vision Conference},
  title     = {A Combined Corner and Edge Detector},
  year      = {1988},
  volume    = {15},
  file      = {:papers/Harris1988 - A Combined Corner and Edge Detector.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://api.semanticscholar.org/CorpusID:1694378}
}


@inproceedings{Havrylov2017,
  author    = {Serhii Havrylov and Ivan Titov},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}},
  title     = {Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols},
  year      = {2017},
  editor    = {Isabelle Guyon and Ulrike von Luxburg and Samy Bengio and Hanna M. Wallach and Rob Fergus and S. V. N. Vishwanathan and Roman Garnett},
  pages     = {2149--2159},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/nips/HavrylovT17.bib},
  file      = {:papers/Havrylov2017 - Emergence of Language with Multi Agent Games_ Learning to Communicate with Sequences of Symbols.pdf:PDF},
  groups    = {MLT Thesis},
  timestamp = {Thu, 21 Jan 2021 15:15:21 +0100},
  url       = {https://proceedings.neurips.cc/paper/2017/hash/70222949cc0db89ab32c9969754d4758-Abstract.html}
}

@inproceedings{He2016,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Deep Residual Learning for Image Recognition},
  year      = {2016},
  pages     = {770-778},
  doi       = {10.1109/CVPR.2016.90},
  file      = {:papers/He2016 - Deep Residual Learning for Image Recognition.pdf:PDF},
  groups    = {MLT Thesis},
  ranking   = {rank2}
}

@misc{Herdade2020,
  author        = {Simao Herdade and Armin Kappeler and Kofi Boakye and Joao Soares},
  title         = {Image Captioning: Transforming Objects into Words},
  year          = {2020},
  archiveprefix = {arXiv},
  doi           = {10.48550/arxiv.1906.05963},
  eprint        = {1906.05963},
  file          = {:papers/Herdade2020 - Image Captioning_ Transforming Objects into Words.pdf:PDF},
  groups        = {MLT Thesis},
  primaryclass  = {cs.CV}
}

@article{Hill2020,
  author        = {Felix Hill and Olivier Tieleman and Tamara von Glehn and Nathaniel Wong and Hamza Merzic and Stephen Clark},
  title         = {Grounded Language Learning Fast and Slow},
  year          = {2020},
  month         = sep,
  abstract      = {Recent work has shown that large text-based neural language models, trained with conventional supervised learning objectives, acquire a surprising propensity for few- and one-shot learning. Here, we show that an embodied agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional reinforcement learning algorithms. After a single introduction to a novel object via continuous visual perception and a language prompt ("This is a dax"), the agent can re-identify the object and manipulate it as instructed ("Put the dax on the bed"). In doing so, it seamlessly integrates short-term, within-episode knowledge of the appropriate referent for the word "dax" with long-term lexical and motor knowledge acquired across episodes (i.e. "bed" and "putting"). We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful for later executing instructions. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for agents that interact with human users.},
  archiveprefix = {arXiv},
  doi           = {10.48550/arxiv.2009.01719},
  eprint        = {2009.01719},
  file          = {:papers/Hill2020 - Grounded Language Learning Fast and Slow.pdf:PDF},
  groups        = {AI: Cognitive System, MLT Thesis, Referring expressions, RE resolution},
  keywords      = {cs.CL, cs.AI},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  readstatus    = {skimmed}
}

@article{Hill2019,
  author        = {Hill, Felix and Lampinen, Andrew and Schneider, Rosalia and Clark, Stephen and Botvinick, Matthew and McClelland, James L. and Santoro, Adam},
  title         = {Environmental drivers of systematicity and generalization in a situated agent},
  year          = {2019},
  month         = oct,
  abstract      = {The question of whether deep neural networks are good at generalising beyond their immediate training experience is of critical importance for learning-based approaches to AI. Here, we consider tests of out-of-sample generalisation that require an agent to respond to never-seen-before instructions by manipulating and positioning objects in a 3D Unity simulated room. We first describe a comparatively generic agent architecture that exhibits strong performance on these tests. We then identify three aspects of the training regime and environment that make a significant difference to its performance: (a) the number of object/word experiences in the training set; (b) the visual invariances afforded by the agent's perspective, or frame of reference; and (c) the variety of visual input inherent in the perceptual aspect of the agent's perception. Our findings indicate that the degree of generalisation that networks exhibit can depend critically on particulars of the environment in which a given task is instantiated. They further suggest that the propensity for neural networks to generalise in systematic ways may increase if, like human children, those networks have access to many frames of richly varying, multi-modal observations as they learn.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1910.00571},
  eprint        = {1910.00571},
  file          = {:papers/Hill2019 - Environmental Drivers of Systematicity and Generalization in a Situated Agent.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.AI},
  publisher     = {arXiv}
}

@inproceedings{Hu2016,
  author    = {Hu, Ronghang and Xu, Huazhe and Rohrbach, Marcus and Feng, Jiashi and Saenko, Kate and Darrell, Trevor},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Natural Language Object Retrieval},
  year      = {2016},
  month     = {June},
  pages     = {4555-4564},
  abstract  = {In this paper, we address the task of natural language object retrieval, to localize a target object within a given image based on a natural language query of the object. Natural language object retrieval differs from text-based image retrieval task as it involves spatial information about objects within the scene and global scene context. To address this issue, we propose a novel Spatial Context Recurrent ConvNet (SCRC) model as scoring function on candidate boxes for object retrieval, integrating spatial configurations and global scene-level contextual information into the network. Our model processes query text, local image descriptors, spatial configurations and global context features through a recurrent network, outputs the probability of the query text conditioned on each candidate box as a score for the box, and can transfer visual-linguistic knowledge from image captioning domain to our task. Experimental results demonstrate that our method effectively utilizes both local and global information, outperforming previous baseline methods significantly on different datasets and scenarios, and can exploit large scale vision and language datasets for knowledge transfer.},
  doi       = {10.1109/CVPR.2016.493},
  file      = {:papers/Hu2016 - Natural Language Object Retrieval.pdf:PDF},
  groups    = {Referring expressions, RE resolution, MLT Thesis,},
  issn      = {1063-6919}
}

@inproceedings{Ilinykh2022,
  author    = {Ilinykh, Nikolai and Emampoor, Yasmeen and Dobnik, Simon},
  booktitle = {Proceedings of the 15th International Conference on Natural Language Generation},
  title     = {Look and Answer the Question: On the Role of Vision in Embodied Question Answering},
  year      = {2022},
  address   = {Waterville, Maine, USA and virtual meeting},
  month     = jul,
  pages     = {236--245},
  publisher = {Association for Computational Linguistics},
  file      = {:papers/Ilinykh2022 - Look and Answer the Question_ on the Role of Vision in Embodied Question Answering.pdf:PDF},
  groups    = {MLT Thesis, Grounding, Referring expressions, RE resolution},
  url       = {https://aclanthology.org/2022.inlg-main.19}
}


@inproceedings{Jang2017,
  author     = {Eric Jang and Shixiang Gu and Ben Poole},
  booktitle  = {5th International Conference on Learning Representations, {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  title      = {Categorical Reparameterization with Gumbel-Softmax},
  year       = {2017},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/conf/iclr/JangGP17.bib},
  file       = {:papers/Jang2017 - Categorical Reparameterization with Gumbel Softmax.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed},
  timestamp  = {Thu, 25 Jul 2019 14:26:04 +0200},
  url        = {https://openreview.net/forum?id=rkE3y85ee}
}

@inproceedings{Ji2022,
  author    = {Ji, Anya and Kojima, Noriyuki and Rush, Noah and Suhr, Alane and Vong, Wai Keen and Hawkins, Robert and Artzi, Yoav},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  title     = {Abstract Visual Reasoning with Tangram Shapes},
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  month     = dec,
  pages     = {582--601},
  publisher = {Association for Computational Linguistics},
  abstract  = {We introduce KiloGram, a resource for studying abstract visual reasoning in humans and machines. Drawing on the history of tangram puzzles as stimuli in cognitive science, we build a richly annotated dataset that, with {\textgreater}1k distinct stimuli, is orders of magnitude larger and more diverse than prior resources. It is both visually and linguistically richer, moving beyond whole shape descriptions to include segmentation maps and part labels. We use this resource to evaluate the abstract visual reasoning capacities of recent multi-modal models. We observe that pre-trained weights demonstrate limited abstract reasoning, which dramatically improves with fine-tuning. We also observe that explicitly describing parts aids abstract reasoning for both humans and models, especially when jointly encoding the linguistic and visual inputs.},
  file      = {:papers/Ji2022 - Abstract Visual Reasoning with Tangram Shapes.pdf:PDF},
  groups    = {MLT Thesis, Grounding, Referring expressions},
  url       = {https://aclanthology.org/2022.emnlp-main.38}
}

@inproceedings{Johnson2017a,
  author        = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
  booktitle     = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  title         = {CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  year          = {2017},
  month         = dec,
  pages         = {2901--2910},
  publisher     = {arXiv},
  abstract      = {When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/JohnsonHMFZG16.bib},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1612.06890},
  eprint        = {1612.06890},
  eprinttype    = {arxiv},
  file          = {:papers/Johnson2017a - CLEVR_ a Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning.pdf:PDF},
  groups        = {MLT Thesis},
  journal       = {CoRR},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  timestamp     = {Sat, 19 Oct 2019 16:30:04 +0200}
}

@inproceedings{Johnson2017,
  author    = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Hoffman, Judy and Fei-Fei, Li and Zitnick, C Lawrence and Girshick, Ross},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  title     = {Inferring and Executing Programs for Visual Reasoning},
  year      = {2017},
  pages     = {2989--2998},
  file      = {:papers/Johnson2017 - Inferring and Executing Programs for Visual Reasoning.pdf:PDF},
  groups    = {MLT Thesis, Grounding, Referring expressions, RE resolution}
}

@inproceedings{Kelleher2020,
  author    = {John D. Kelleher and Dobnik, Simon},
  booktitle = {CLASP Papers in Computational Linguistics: Dialogue and Perception -- Extended papers from DaP-2018 Gothenburg},
  title     = {Referring to the recently seen: reference and perceptual memory in situated dialogue},
  year      = {2020},
  pages     = {41--50},
  abstract  = {From theoretical linguistic and cognitive perspectives, situated dialogue systems are interesting as they provide ideal test-beds for investigating the interaction between language and perception. To date, how- ever much of the work on situated dialogue has focused resolving anaphoric or exophoric references. This paper opens up the question of how perceptual memory and linguistic references interact, and the challenges that this poses to computational models of perceptually grounded dialogue.},
  crossref  = {DaP-2018-Extended},
  file      = {:papers/Kelleher2020 - Referring to the Recently Seen_ Reference and Perceptual Memory in Situated Dialogue.pdf:PDF},
  groups    = {MLT Thesis, Referring expressions, Grounding},
  keywords  = {situated dialogue, reference resolution, perception, memory},
  url       = {https://gup.ub.gu.se/publication/294891?lang=en}
}

@inproceedings{Kelleher2017,
  author       = {Kelleher, John D. and Dobnik, Simon},
  booktitle    = {Proceedings of the Conference on Logic and Machine Learning in Natural Language (LaML 2017)},
  title        = {What is not where: the challenge of integrating spatial representations into deep learning architectures},
  year         = {2017},
  address      = {Gothenburg},
  editor       = {Dobnik, Simon; Lappin, Shalom},
  month        = jun,
  organization = {University of Gothenburg},
  publisher    = {Centre for Linguistic Theory and Studies in Probability (CLASP)},
  file         = {:papers/Kelleher2017 - What Is Not Where_ the Challenge of Integrating Spatial Representations into Deep Learning Architectures.pdf:PDF},
  groups       = {MLT Thesis, Referring expressions, Grounding, RE generation}
}

@inproceedings{Kharitonov2020,
  author     = {Kharitonov, Eugene and Baroni, Marco},
  booktitle  = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  title      = {Emergent Language Generalization and Acquisition Speed are not tied to Compositionality},
  year       = {2020},
  address    = {Online},
  month      = nov,
  pages      = {11--15},
  publisher  = {Association for Computational Linguistics},
  abstract   = {Studies of discrete languages emerging when neural agents communicate to solve a joint task often look for evidence of compositional structure. This stems for the expectation that such a structure would allow languages to be acquired faster by the agents and enable them to generalize better. We argue that these beneficial properties are only loosely connected to compositionality. In two experiments, we demonstrate that, depending on the task, non-compositional languages might show equal, or better, generalization performance and acquisition speed than compositional ones. Further research in the area should be clearer about what benefits are expected from compositionality, and how the latter would lead to them.},
  doi        = {10.18653/v1/2020.blackboxnlp-1.2},
  file       = {:papers/Kharitonov2020 - Emergent Language Generalization and Acquisition Speed Are Not Tied to Compositionality.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {read},
  url        = {https://aclanthology.org/2020.blackboxnlp-1.2}
}

@article{Kharitonov2019a,
  author        = {Kharitonov, Eugene and Chaabouni, Rahma and Bouchacourt, Diane and Baroni, Marco},
  title         = {Entropy Minimization In Emergent Languages},
  year          = {2019},
  month         = may,
  abstract      = {There is growing interest in studying the languages that emerge when neural agents are jointly trained to solve tasks requiring communication through a discrete channel. We investigate here the information-theoretic complexity of such languages, focusing on the basic two-agent, one-exchange setup. We find that, under common training procedures, the emergent languages are subject to an entropy minimization pressure that has also been detected in human language, whereby the mutual information between the communicating agent's inputs and the messages is minimized, within the range afforded by the need for successful communication. That is, emergent languages are (nearly) as simple as the task they are developed for allow them to be. This pressure is amplified as we increase communication channel discreteness. Further, we observe that stronger discrete-channel-driven entropy minimization leads to representations with increased robustness to overfitting and adversarial attacks. We conclude by discussing the implications of our findings for the study of natural and artificial communication systems.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.13687},
  eprint        = {1905.13687},
  file          = {:papers/Kharitonov2019a - Entropy Minimization in Emergent Languages.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{Kharitonov2019,
  author     = {Kharitonov, Eugene and Chaabouni, Rahma and Bouchacourt, Diane and Baroni, Marco},
  booktitle  = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations},
  title      = {{EGG}: a toolkit for research on Emergence of lan{G}uage in Games},
  year       = {2019},
  address    = {Hong Kong, China},
  month      = nov,
  pages      = {55--60},
  publisher  = {Association for Computational Linguistics},
  abstract   = {There is renewed interest in simulating language emergence among deep neural agents that communicate to jointly solve a task, spurred by the practical aim to develop language-enabled interactive AIs, as well as by theoretical questions about the evolution of human language. However, optimizing deep architectures connected by a discrete communication channel (such as that in which language emerges) is technically challenging. We introduce EGG, a toolkit that greatly simplifies the implementation of emergent-language communication games. EGG{'}s modular design provides a set of building blocks that the user can combine to create new games, easily navigating the optimization and architecture space. We hope that the tool will lower the technical barrier, and encourage researchers from various backgrounds to do original work in this exciting area.},
  doi        = {10.18653/v1/D19-3010},
  file       = {:papers/Kharitonov2019 - EGG_ a Toolkit for Research on Emergence of LanGuage in Games.pdf:PDF},
  groups     = {MLT Thesis},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://aclanthology.org/D19-3010}
}

@inproceedings{Kingma2015,
  author     = {Diederik P. Kingma and Jimmy Ba},
  booktitle  = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  title      = {Adam: {A} Method for Stochastic Optimization},
  year       = {2015},
  editor     = {Yoshua Bengio and Yann LeCun},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  eprint     = {1412.6980},
  eprinttype = {arxiv},
  file       = {:papers/Kingma2015 - Adam_ a Method for Stochastic Optimization.pdf:PDF},
  groups     = {MLT Thesis},
  timestamp  = {Thu, 25 Jul 2019 14:25:37 +0200}
}

@article{Kirby2002,
  author  = {Kirby, Simon},
  journal = {Artificial Life},
  title   = {Natural Language From Artificial Life},
  year    = {2002},
  number  = {2},
  pages   = {185-215},
  volume  = {8},
  doi     = {10.1162/106454602320184248},
  file    = {:papers/Kirby2002 - Natural Language from Artificial Life.pdf:PDF},
  groups  = {MLT Thesis}
}

@article{Kirby2008,
  author   = {Simon Kirby and Hannah Cornish and Kenny Smith},
  journal  = {Proceedings of the National Academy of Sciences},
  title    = {Cumulative cultural evolution in the laboratory: An experimental approach to the origins of structure in human language},
  year     = {2008},
  number   = {31},
  pages    = {10681-10686},
  volume   = {105},
  abstract = {We introduce an experimental paradigm for studying the cumulative cultural evolution of language. In doing so we provide the first experimental validation for the idea that cultural transmission can lead to the appearance of design without a designer. Our experiments involve the iterated learning of artificial languages by human participants. We show that languages transmitted culturally evolve in such a way as to maximize their own transmissibility: over time, the languages in our experiments become easier to learn and increasingly structured. Furthermore, this structure emerges purely as a consequence of the transmission of language over generations, without any intentional design on the part of individual language learners. Previous computational and mathematical models suggest that iterated learning provides an explanation for the structure of human language and link particular aspects of linguistic structure with particular constraints acting on language during its transmission. The experimental work presented here shows that the predictions of these models, and models of cultural evolution more generally, can be tested in the laboratory.},
  doi      = {10.1073/pnas.0707835105},
  file     = {:papers/Kirby2008 - Cumulative Cultural Evolution in the Laboratory_ an Experimental Approach to the Origins of Structure in Human Language.pdf:PDF},
  groups   = {MLT Thesis}
}

@inproceedings{Klymenko2022,
  author    = {Klymenko, Oleksandra and Meisenbacher, Stephen and Matthes, Florian},
  booktitle = {Proceedings of the Fourth Workshop on Privacy in Natural Language Processing},
  title     = {Differential Privacy in Natural Language Processing The Story So Far},
  year      = {2022},
  address   = {Seattle, United States},
  month     = jul,
  pages     = {1--11},
  publisher = {Association for Computational Linguistics},
  abstract  = {As the tide of Big Data continues to influence the landscape of Natural Language Processing (NLP), the utilization of modern NLP methods has grounded itself in this data, in order to tackle a variety of text-based tasks. These methods without a doubt can include private or otherwise personally identifiable information. As such, the question of privacy in NLP has gained fervor in recent years, coinciding with the development of new Privacy- Enhancing Technologies (PETs). Among these PETs, Differential Privacy boasts several desirable qualities in the conversation surrounding data privacy. Naturally, the question becomes whether Differential Privacy is applicable in the largely unstructured realm of NLP. This topic has sparked novel research, which is unified in one basic goal how can one adapt Differential Privacy to NLP methods? This paper aims to summarize the vulnerabilities addressed by Differential Privacy, the current thinking, and above all, the crucial next steps that must be considered.},
  doi       = {10.18653/v1/2022.privatenlp-1.1},
  file      = {:papers/Klymenko2022 - Differential Privacy in Natural Language Processing the Story so Far.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2022.privatenlp-1.1}
}

@inproceedings{Kollar2010,
  author    = {Kollar, Thomas and Tellex, Stefanie and Roy, Deb and Roy, Nicholas},
  booktitle = {2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title     = {Toward understanding natural language directions},
  year      = {2010},
  pages     = {259-266},
  doi       = {10.1109/HRI.2010.5453186},
  file      = {:papers/Kollar2010 - Toward Understanding Natural Language Directions.pdf:PDF},
  groups    = {Grounding, MLT Thesis,}
}

@inproceedings{Kottur2017,
  author     = {Kottur, Satwik and Moura, Jos{\'e} and Lee, Stefan and Batra, Dhruv},
  booktitle  = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  title      = {Natural Language Does Not Emerge {`}Naturally{'} in Multi-Agent Dialog},
  year       = {2017},
  address    = {Copenhagen, Denmark},
  editor     = {Palmer, Martha and Hwa, Rebecca and Riedel, Sebastian},
  month      = sep,
  pages      = {2962--2967},
  publisher  = {Association for Computational Linguistics},
  abstract   = {A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, learned without any human supervision! In this paper, using a Task {\&} Talk reference game between two agents as a testbed, we present a sequence of {`}negative{'} results culminating in a {`}positive{'} one {--} showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge {`}naturally{'},despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate.},
  doi        = {10.18653/v1/D17-1321},
  file       = {:papers/Kottur2017 - Natural Language Does Not Emerge 'Naturally' in Multi Agent Dialog.pdf:PDF},
  groups     = {MLT Thesis},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://aclanthology.org/D17-1321}
}

@article{Krahmer2012,
  author    = {Krahmer, Emiel and van Deemter, Kees},
  journal   = {Computational Linguistics},
  title     = {Computational Generation of Referring Expressions: A Survey},
  year      = {2012},
  month     = mar,
  number    = {1},
  pages     = {173--218},
  volume    = {38},
  address   = {Cambridge, MA},
  doi       = {10.1162/COLI_a_00088},
  file      = {:papers/Krahmer2012 - Computational Generation of Referring Expressions_ a Survey.pdf:PDF},
  groups    = {MLT Thesis, Referring expressions, Grounding},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/J12-1006}
}

@article{Landau1998,
  author   = {Barbara Landau and Linda Smith and Susan Jones},
  journal  = {Trends in Cognitive Sciences},
  title    = {Object perception and object naming in early development},
  year     = {1998},
  issn     = {1364-6613},
  number   = {1},
  pages    = {19-24},
  volume   = {2},
  abstract = {Among our most fundamental capacities are those that allow us to perceive, categorize and name objects. Recently, controversy has surrounded the question of how young children learn names for objects, in particular, the relative roles of perception and higher-level world knowledge. It is well known that adults depend strongly on conceptual knowledge in a variety of categorization tasks, including object naming. We argue, however, that perception may play a special role in early object naming and, in particular, that certain kinds of world knowledge known to guide adult naming may come to guide naming only rather late in development. Building early mechanisms of naming on a perceptual foundation that may be encapsulated, and thus shut off from more reflective processes, may explain in part why young children can easily and rapidly learn names for things from the adults around them, despite the fact that adults and children may possess very different conceptual organizations.},
  doi      = {https://doi.org/10.1016/S1364-6613(97)01111-X},
  file     = {:papers/Landau1998 - Object Perception and Object Naming in Early Development.pdf:PDF},
  groups   = {Grounding, MLT Thesis, Referring expressions},
  keywords = {object, development, language, perception, naming, categorization},
  url      = {https://www.sciencedirect.com/science/article/pii/S136466139701111X}
}

@article{Larsson2018,
  author   = {Larsson, Staffan},
  journal  = {Topics in Cognitive Science},
  title    = {Grounding as a Side-Effect of Grounding},
  year     = {2018},
  number   = {2},
  pages    = {389-408},
  volume   = {10},
  abstract = {Abstract In relation to semantics, “grounding” has (at least) two relevant meanings. “Symbol grounding” is the process of connecting symbols (e.g., words) to perception and the world. “Communicative grounding” is the process of interactively adding to common ground in dialog. Strategies for grounding in human communication include, crucially, strategies for resolving troubles caused by various kinds of miscommunication. As it happens, these two processes of grounding are closely related. As a side-effect of grounding an utterance, dialog participants (DPs) may adjust the meanings they assign to linguistic expressions, in a process of semantic coordination. Meanings of at least some expressions (e.g., concrete nouns) include perceptual aspects which enable DPs to classify entities as falling under the expression or not based on their perception of those entities. We show how perceptual grounding of symbols can be achieved in a process of interactively adding to common ground. This requires that perceptual aspects of meaning can be updated as a result of participating in linguistic interaction, thereby enabling fine-grained semantic coordination of perceptually grounded linguistic meanings. A formal semantics for low-level perceptual aspects of meaning is presented, tying these together with the logical-inferential aspects of meaning traditionally studied in formal semantics. The key idea is to model perceptual meanings as classifiers of perceptual input. This requires a framework where intensions are (a) represented independently of extensions, and (b) structured objects which can be modified as a result of learning. We use Type Theory with Records (TTR), a formal semantics framework which starts from the idea that information and meaning are founded on our ability to perceive and classify the world, that is, to perceive objects and situations as being of types. As an example of our approach, we show how a simple classifier of spatial information based on the Perceptron can be cast in TTR.},
  doi      = {https://doi.org/10.1111/tops.12317},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12317},
  file     = {:papers/Larsson2018 - Grounding As a Side Effect of Grounding.pdf:PDF},
  groups   = {Grounding, MLT Thesis},
  keywords = {Grounding, Dialog, Formal semantics, Perception, Cognition, Learning},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12317}
}

@article{Lauria2001,
  author    = {S. Lauria and G. Bugmann and T. Kyriacou and J. Bos and A. Klein},
  journal   = {{IEEE} Intelligent Systems},
  title     = {Training personal robots using natural language instruction},
  year      = {2001},
  number    = {5},
  pages     = {38--45},
  volume    = {16},
  doi       = {10.1109/mis.2001.956080},
  file      = {:papers/Lauria2001 - Training Personal Robots Using Natural Language Instruction.pdf:PDF},
  groups    = {AI: Cognitive System, Grounding, MLT Thesis},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})}
}

@article{Lazaridou2020,
  author        = {Lazaridou, Angeliki and Baroni, Marco},
  title         = {Emergent Multi-Agent Communication in the Deep Learning Era},
  year          = {2020},
  month         = jun,
  abstract      = {The ability to cooperate through language is a defining feature of humans. As the perceptual, motory and planning capabilities of deep artificial networks increase, researchers are studying whether they also can develop a shared language to interact. From a scientific perspective, understanding the conditions under which language evolves in communities of deep agents and its emergent features can shed light on human language evolution. From an applied perspective, endowing deep networks with the ability to solve problems interactively by communicating with each other and with us should make them more flexible and useful in everyday life. This article surveys representative recent language emergence studies from both of these two angles.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2006.02419},
  eprint        = {2006.02419},
  file          = {:papers/Lazaridou2020 - Emergent Multi Agent Communication in the Deep Learning Era.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio1},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{Lazaridou2017,
  author        = {Angeliki Lazaridou and Alexander Peysakhovich and Marco Baroni},
  booktitle     = {International Conference on Learning Representations},
  title         = {Multi-Agent Cooperation and the Emergence of (Natural) Language},
  year          = {2017},
  month         = dec,
  abstract      = {The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the "word meanings" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively.},
  archiveprefix = {arXiv},
  doi           = {10.48550/arxiv.1612.07182},
  eprint        = {1612.07182},
  file          = {:papers/Lazaridou2017 - Multi Agent Cooperation and the Emergence of (Natural) Language.pdf:PDF},
  groups        = {AI: Cognitive System, MLT Thesis},
  keywords      = {cs.CL, cs.CV, cs.GT, cs.LG, cs.MA},
  primaryclass  = {cs.CL},
  readstatus    = {read}
}

@inproceedings{Lazaridou2018,
  author    = {Angeliki Lazaridou and Karl Moritz Hermann and Karl Tuyls and Stephen Clark},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input},
  year      = {2018},
  file      = {:papers/Lazaridou2018 - Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://openreview.net/forum?id=HJGv1Z-AW}
}

@inproceedings{Lee2017,
  author    = {Lee, Kenton and He, Luheng and Lewis, Mike and Zettlemoyer, Luke},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  title     = {End-to-end Neural Coreference Resolution},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  editor    = {Palmer, Martha and Hwa, Rebecca and Riedel, Sebastian},
  month     = sep,
  pages     = {188--197},
  publisher = {Association for Computational Linguistics},
  abstract  = {We introduce the first end-to-end coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or hand-engineered mention detector. The key idea is to directly consider all spans in a document as potential mentions and learn distributions over possible antecedents for each. The model computes span embeddings that combine context-dependent boundary representations with a head-finding attention mechanism. It is trained to maximize the marginal likelihood of gold antecedent spans from coreference clusters and is factored to enable aggressive pruning of potential mentions. Experiments demonstrate state-of-the-art performance, with a gain of 1.5 F1 on the OntoNotes benchmark and by 3.1 F1 using a 5-model ensemble, despite the fact that this is the first approach to be successfully trained with no external resources.},
  doi       = {10.18653/v1/D17-1018},
  file      = {:papers/Lee2017 - End to End Neural Coreference Resolution.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/D17-1018}
}

@inproceedings{Lee2022,
  author    = {Lee, Jae Hee and Kerzel, Matthias and Ahrens, Kyra and Weber, Cornelius and Wermter, Stefan},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, {IJCAI-22}},
  title     = {What is Right for Me is Not Yet Right for You: A Dataset for Grounding Relative Directions via Multi-Task Learning},
  year      = {2022},
  editor    = {Lud De Raedt},
  month     = {7},
  note      = {Main Track},
  pages     = {1039--1045},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  doi       = {10.24963/ijcai.2022/145},
  file      = {:papers/Lee2022 - What Is Right for Me Is Not yet Right for You_ a Dataset for Grounding Relative Directions Via Multi Task Learning.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://doi.org/10.24963/ijcai.2022/145}
}

@book{Lewis1969,
  author    = {David Kellogg Lewis},
  publisher = {Cambridge, MA, USA: Wiley-Blackwell},
  title     = {Convention: A Philosophical Study},
  year      = {1969},
  groups    = {MLT Thesis}
}

@inproceedings{Liu2022,
  author    = {Liu, Yinhong and Emerson, Guy},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {Learning Functional Distributional Semantics with Visual Data},
  year      = {2022},
  address   = {Dublin, Ireland},
  month     = may,
  pages     = {3976--3988},
  publisher = {Association for Computational Linguistics},
  abstract  = {Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.},
  doi       = {10.18653/v1/2022.acl-long.275},
  file      = {:papers/Liu2022 - Learning Functional Distributional Semantics with Visual Data.pdf:PDF},
  groups    = {MLT Thesis, Referring expressions, Grounding},
  url       = {https://aclanthology.org/2022.acl-long.275}
}

@misc{Liu2022a,
  author     = {Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  title      = {Visual Spatial Reasoning},
  year       = {2022},
  copyright  = {Creative Commons Attribution 4.0 International},
  doi        = {10.48550/ARXIV.2205.00363},
  eprint     = {2205.00363},
  eprinttype = {arxiv},
  file       = {:papers/Liu2022a - Visual Spatial Reasoning.pdf:PDF},
  groups     = {MLT Thesis, Grounding, Referring expressions, RE resolution, RE generation},
  keywords   = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher  = {arXiv}
}

@inproceedings{Loaiciga2021,
  author    = {Lo{\'a}iciga, Sharid and Dobnik, Simon and Schlangen, David},
  booktitle = {Proceedings of the Second Workshop on Advances in Language and Vision Research},
  title     = {Reference and coreference in situated dialogue},
  year      = {2021},
  address   = {Online},
  editor    = {{Xin} and Hu, Ronghang and Hudson, Drew and Fu, Tsu-Jui and Rohrbach, Marcus and Fried, Daniel},
  month     = jun,
  pages     = {39--44},
  publisher = {Association for Computational Linguistics},
  abstract  = {In recent years several corpora have been developed for vision and language tasks. We argue that there is still significant room for corpora that increase the complexity of both visual and linguistic domains and which capture different varieties of perceptual and conversational contexts. Working with two corpora approaching this goal, we present a linguistic perspective on some of the challenges in creating and extending resources combining language and vision while preserving continuity with the existing best practices in the area of coreference annotation.},
  doi       = {10.18653/v1/2021.alvr-1.7},
  file      = {:papers/Loaiciga2021 - Reference and Coreference in Situated Dialogue.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/2021.alvr-1.7}
}

@inproceedings{Lowe1999,
  author     = {D.G. Lowe},
  booktitle  = {Proceedings of the Seventh {IEEE} International Conference on Computer Vision},
  title      = {Object recognition from local scale-invariant features},
  year       = {1999},
  publisher  = {{IEEE}},
  doi        = {10.1109/iccv.1999.790410},
  file       = {:papers/Lowe1999 - Object Recognition from Local Scale Invariant Features.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@inproceedings{Lu2021,
  author    = {Lu, Pengcheng and Poesio, Massimo},
  booktitle = {Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference},
  title     = {Coreference Resolution for the Biomedical Domain: A Survey},
  year      = {2021},
  address   = {Punta Cana, Dominican Republic},
  editor    = {Ogrodniczuk, Maciej and Pradhan, Sameer and Poesio, Massimo and Grishina, Yulia and Ng, Vincent},
  month     = nov,
  pages     = {12--23},
  publisher = {Association for Computational Linguistics},
  abstract  = {Issues with coreference resolution are one of the most frequently mentioned challenges for information extraction from the biomedical literature. Thus, the biomedical genre has long been the second most researched genre for coreference resolution after the news domain, and the subject of a great deal of research for NLP in general. In recent years this interest has grown enormously leading to the development of a number of substantial datasets, of domain-specific contextual language models, and of several architectures. In this paper we review the state of-the-art of coreference in the biomedical domain with a particular attention on these most recent developments.},
  doi       = {10.18653/v1/2021.crac-1.2},
  file      = {:papers/Lu2021 - Coreference Resolution for the Biomedical Domain_ a Survey.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/2021.crac-1.2}
}

@inproceedings{Lu2017,
  author     = {Lu, Jiasen and Xiong, Caiming and Parikh, Devi and Socher, Richard},
  booktitle  = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title      = {Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning},
  year       = {2017},
  pages      = {3242-3250},
  doi        = {10.1109/CVPR.2017.345},
  file       = {:papers/Lu2017 - Knowing When to Look_ Adaptive Attention Via a Visual Sentinel for Image Captioning.pdf:PDF},
  groups     = {MLT Thesis, Referring expressions, Grounding},
  priority   = {prio1},
  readstatus = {read}
}

@inproceedings{Lu2019,
  author    = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  year      = {2019},
  pages     = {13--23},
  file      = {:papers/Lu2019 - Vilbert_ Pretraining Task Agnostic Visiolinguistic Representations for Vision and Language Tasks.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis}
}

@inproceedings{Mao2016,
  author    = {Mao, Junhua and Huang, Jonathan and Toshev, Alexander and Camburu, Oana and Yuille, Alan and Murphy, Kevin},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Generation and Comprehension of Unambiguous Object Descriptions},
  year      = {2016},
  month     = {June},
  pages     = {11-20},
  abstract  = {We propose a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image, and which can also comprehend or interpret such an expression to infer which object is being described. We show that our method outperforms previous methods that generate descriptions of objects without taking into account other potentially ambiguous objects in the scene. Our model is inspired by recent successes of deep learning methods for image captioning, but while image captioning is difficult to evaluate, our task allows for easy objective evaluation. We also present a new large-scale dataset for referring expressions, based on MSCOCO. We have released the dataset and a toolbox for visualization and evaluation, see https://github.com/ mjhucla/Google_Refexp_toolbox.},
  doi       = {10.1109/CVPR.2016.9},
  file      = {:papers/Mao2016 - Generation and Comprehension of Unambiguous Object Descriptions.pdf:PDF},
  groups    = {Referring expressions, MLT Thesis, RE resolution,},
  issn      = {1063-6919}
}

@inproceedings{Martin2020,
  author    = {Martin, Scott and Poddar, Shivani and Upasani, Kartikeya},
  booktitle = {Proceedings of the Twelfth Language Resources and Evaluation Conference},
  title     = {{M}u{D}o{C}o: Corpus for Multidomain Coreference Resolution and Referring Expression Generation},
  year      = {2020},
  address   = {Marseille, France},
  editor    = {Calzolari, Nicoletta and B{\'e}chet, Fr{\'e}d{\'e}ric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, H{\'e}l{\`e}ne and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios},
  month     = may,
  pages     = {104--111},
  publisher = {European Language Resources Association},
  abstract  = {This paper proposes a new dataset, MuDoCo, composed of authored dialogs between a fictional user and a system who are given tasks to perform within six task domains. These dialogs are given rich linguistic annotations by expert linguists for several types of reference mentions and named entity mentions, either of which can span multiple words, as well as for coreference links between mentions. The dialogs sometimes cross and blend domains, and the users exhibit complex task switching behavior such as re-initiating a previous task in the dialog by referencing the entities within it. The dataset contains a total of 8,429 dialogs with an average of 5.36 turns per dialog. We are releasing this dataset to encourage research in the field of coreference resolution, referring expression generation and identification within realistic, deep dialogs involving multiple domains. To demonstrate its utility, we also propose two baseline models for the downstream tasks: coreference resolution and referring expression generation.},
  file      = {:papers/Martin2020 - MuDoCo_ Corpus for Multidomain Coreference Resolution and Referring Expression Generation.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  isbn      = {979-10-95546-34-4},
  language  = {English},
  url       = {https://aclanthology.org/2020.lrec-1.13}
}

@inproceedings{Mitchell2013,
  author    = {Mitchell, Margaret and van Deemter, Kees and Reiter, Ehud},
  booktitle = {Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  title     = {Generating Expressions that Refer to Visible Objects},
  year      = {2013},
  address   = {Atlanta, Georgia},
  month     = jun,
  pages     = {1174--1184},
  publisher = {Association for Computational Linguistics},
  file      = {:papers/Mitchell2013 - Generating Expressions That Refer to Visible Objects.pdf:PDF},
  groups    = {MLT Thesis, Grounding, Referring expressions, RE generation},
  url       = {https://aclanthology.org/N13-1137}
}

@article{Monroe2017,
  author   = {Will Monroe and Robert Hawkins and Noah Goodman and Christopher Potts},
  journal  = {Transactions of the Association for Computational Linguistics},
  title    = {Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding},
  year     = {2017},
  issn     = {2307-387X},
  number   = {0},
  pages    = {325--338},
  volume   = {5},
  abstract = {We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives. We observe that pragmatic reasoning helps primarily in the hardest cases: when the model must distinguish very similar colors, or when few utterances adequately express the target color. Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors. We also show that the embedded speaker model reproduces many of these pragmatic behaviors.},
  file     = {:papers/Monroe2017 - Colors in Context_ a Pragmatic Neural Model for Grounded Language Understanding.pdf:PDF},
  groups   = {MLT Thesis, Grounding, Referring expressions},
  url      = {https://transacl.org/ojs/index.php/tacl/article/view/1142}
}

@misc{Monroe2018,
  author     = {Monroe, Will and Hu, Jennifer and Jong, Andrew and Potts, Christopher},
  title      = {Generating Bilingual Pragmatic Color References},
  year       = {2018},
  copyright  = {Creative Commons Attribution 4.0 International},
  doi        = {10.48550/ARXIV.1803.03917},
  eprint     = {1803.03917},
  eprinttype = {arxiv},
  file       = {:papers/Monroe2018 - Generating Bilingual Pragmatic Color References.pdf:PDF},
  groups     = {MLT Thesis},
  keywords   = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher  = {arXiv}
}

@article{Noukhovitch2021,
  author        = {Noukhovitch, Michael and LaCroix, Travis and Lazaridou, Angeliki and Courville, Aaron},
  title         = {Emergent Communication under Competition},
  year          = {2021},
  month         = jan,
  abstract      = {The literature in modern machine learning has only negative results for learning to communicate between competitive agents using standard RL. We introduce a modified sender-receiver game to study the spectrum of partially-competitive scenarios and show communication can indeed emerge in a competitive setting. We empirically demonstrate three key takeaways for future research. First, we show that communication is proportional to cooperation, and it can occur for partially competitive scenarios using standard learning algorithms. Second, we highlight the difference between communication and manipulation and extend previous metrics of communication to the competitive case. Third, we investigate the negotiation game where previous work failed to learn communication between independent agents (Cao et al., 2018). We show that, in this setting, both agents must benefit from communication for it to emerge; and, with a slight modification to the game, we demonstrate successful communication between competitive agents. We hope this work overturns misconceptions and inspires more research in competitive emergent communication.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  doi           = {10.48550/ARXIV.2101.10276},
  eprint        = {2101.10276},
  file          = {:papers/Noukhovitch2021 - Emergent Communication under Competition.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.LG},
  publisher     = {arXiv}
}

@article{Qiao2020,
  author  = {Yanyuan Qiao and Chaorui Deng and Qi Wu},
  journal = {IEEE Transactions on Multimedia},
  title   = {Referring Expression Comprehension: A Survey of Methods and Datasets},
  year    = {2020},
  pages   = {4426-4440},
  volume  = {23},
  file    = {:papers/Qiao2020 - Referring Expression Comprehension_ a Survey of Methods and Datasets.pdf:PDF},
  groups  = {Referring expressions, RE resolution, MLT Thesis,},
  url     = {https://api.semanticscholar.org/CorpusID:220647240}
}

@inproceedings{Ramisa2015a,
  author    = {Arnau Ramisa and Josiah Wang and Ying Lu and Emmanuel Dellandrea and Francesc Moreno-Noguer and Robert Gaizauskas},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  title     = {Combining Geometric, Textual and Visual Features for Predicting Prepositions in Image Descriptions: Supplementary Material},
  year      = {2015},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/d15-1022},
  file      = {:papers/Ramisa2015a - Combining Geometric, Textual and Visual Features for Predicting Prepositions in Image Descriptions_ Supplementary Material.pdf:PDF},
  groups    = {AI: Cognitive System, MLT Thesis,}
}

@inproceedings{Ramisa2015,
  author     = {Arnau Ramisa and Josiah Wang and Ying Lu and Emmanuel Dellandrea and Francesc Moreno-Noguer and Robert Gaizauskas},
  booktitle  = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  title      = {Combining Geometric, Textual and Visual Features for Predicting Prepositions in Image Descriptions},
  year       = {2015},
  publisher  = {Association for Computational Linguistics},
  doi        = {10.18653/v1/d15-1022},
  file       = {:papers/Ramisa2015 - Combining Geometric, Textual and Visual Features for Predicting Prepositions in Image Descriptions.pdf:PDF},
  groups     = {AI: Cognitive System, MLT Thesis, Referring expressions, Grounding, RE generation},
  readstatus = {read}
}

@book{Regier1996,
  author    = {Regier, Terry},
  publisher = {MIT Press},
  title     = {The human semantic potential: spatial language and constrained connectionism},
  year      = {1996},
  address   = {Cambridge, Massachusetts, London, England},
  groups    = {MLT Thesis, Grounding, Referring expressions}
}

@article{Roy2005,
  author    = {Roy, Deb},
  journal   = {Artificial Intelligence},
  title     = {Semiotic schemas: a framework for grounding language in action and perception},
  year      = {2005},
  issn      = {0004-3702},
  month     = {September},
  number    = {1-2},
  pages     = {170--205},
  volume    = {167},
  address   = {Essex, UK},
  doi       = {10.1016/j.artint.2005.04.007},
  file      = {:papers/Roy2005 - Semiotic Schemas_ a Framework for Grounding Language in Action and Perception.pdf:PDF},
  groups    = {MLT Thesis, Grounding},
  publisher = {Elsevier Science Publishers Ltd.}
}

@article{Roy2002,
  author     = {Deb K. Roy},
  journal    = {Computer Speech, Language},
  title      = {Learning visually grounded words and syntax for a scene description task},
  year       = {2002},
  month      = {jul},
  number     = {3-4},
  pages      = {353--385},
  volume     = {16},
  doi        = {10.1016/s0885-2308(02)00024-4},
  file       = {:papers/Roy2002 - Learning Visually Grounded Words and Syntax for a Scene Description Task.pdf:PDF},
  groups     = {AI: Cognitive System, MLT Thesis, Grounding},
  priority   = {prio1},
  publisher  = {Elsevier {BV}},
  readstatus = {read}
}

@inproceedings{Sanchez2022,
  author    = {S{\'a}nchez, Jorge and Mazuecos, Mauricio and Maina, Hern{\'a}n and Benotti, Luciana},
  booktitle = {Findings of the Association for Computational Linguistics: NAACL 2022},
  title     = {What kinds of errors do reference resolution models make and what can we learn from them?},
  year      = {2022},
  address   = {Seattle, United States},
  editor    = {Carpuat, Marine and de Marneffe, Marie-Catherine and Meza Ruiz, Ivan Vladimir},
  month     = jul,
  pages     = {1971--1986},
  publisher = {Association for Computational Linguistics},
  abstract  = {Referring resolution is the task of identifying the referent of a natural language expression, for example {``}the woman behind the other woman getting a massage{''}. In this paper we investigate which are the kinds of referring expressions on which current transformer based models fail. Motivated by this analysis we identify the weakening of the spatial natural constraints as one of its causes and propose a model that aims to restore it. We evaluate our proposed model on different datasets for the task showing improved performance on the most challenging kinds of referring expressions. Finally we present a thorough analysis of the kinds errors that are improved by the new model and those that are not and remain future challenges for the task.},
  doi       = {10.18653/v1/2022.findings-naacl.152},
  file      = {:papers/Sanchez2022 - What Kinds of Errors Do Reference Resolution Models Make and What Can We Learn from Them_.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/2022.findings-naacl.152}
}

@inproceedings{Shah2020,
  author    = {Shah, Deven Santosh and Schwartz, H. Andrew and Hovy, Dirk},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  title     = {Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview},
  year      = {2020},
  address   = {Online},
  month     = jul,
  pages     = {5248--5264},
  publisher = {Association for Computational Linguistics},
  abstract  = {An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.},
  doi       = {10.18653/v1/2020.acl-main.468},
  file      = {:papers/Shah2020 - Predictive Biases in Natural Language Processing Models_ a Conceptual Framework and Overview.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2020.acl-main.468}
}

@inproceedings{Silberer2014,
  author    = {Silberer, Carina and Lapata, Mirella},
  booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {Learning Grounded Meaning Representations with Autoencoders},
  year      = {2014},
  address   = {Baltimore, Maryland},
  editor    = {Toutanova, Kristina and Wu, Hua},
  month     = jun,
  pages     = {721--732},
  publisher = {Association for Computational Linguistics},
  doi       = {10.3115/v1/P14-1068},
  file      = {:papers/Silberer2014 - Learning Grounded Meaning Representations with Autoencoders.pdf:PDF},
  groups    = {Grounding, MLT Thesis},
  url       = {https://aclanthology.org/P14-1068}
}


@inproceedings{Simonyan2015,
  author     = {Karen Simonyan and Andrew Zisserman},
  booktitle  = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  title      = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  year       = {2015},
  editor     = {Yoshua Bengio and Yann LeCun},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
  eprint     = {1409.1556},
  eprinttype = {arxiv},
  file       = {:papers/Simonyan2015 - Very Deep Convolutional Networks for Large Scale Image Recognition.pdf:PDF},
  groups     = {MLT Thesis},
  timestamp  = {Wed, 17 Jul 2019 10:40:54 +0200}
}

@inproceedings{Skocaj2011,
  author    = {Danijel Skocaj and Matej Kristan and Alen Vrecko and Marko Mahnic and Miroslav Janicek and Geert-Jan M. Kruijff and Marc Hanheide and Nick Hawes and Thomas Keller and Michael Zillich and Kai Zhou},
  booktitle = {2011 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
  title     = {A system for interactive learning in dialogue with a tutor},
  year      = {2011},
  month     = {sep},
  publisher = {{IEEE}},
  doi       = {10.1109/iros.2011.6094926},
  file      = {:papers/Skocaj2011 - A System for Interactive Learning in Dialogue with a Tutor.pdf:PDF},
  groups    = {AI: Cognitive System, MLT Thesis, Grounding}
}

@article{Socher2014,
  author    = {Socher, Richard and Karpathy, Andrej and Le, Quoc V. and Manning, Christopher D. and Ng, Andrew Y.},
  journal   = {Transactions of the Association for Computational Linguistics},
  title     = {Grounded Compositional Semantics for Finding and Describing Images with Sentences},
  year      = {2014},
  pages     = {207--218},
  volume    = {2},
  abstract  = {Previous work on Recursive Neural Networks (RNNs) shows that these models can produce compositional feature vectors for accurately representing and classifying sentences or images. However, the sentence vectors of previous models cannot accurately represent visually grounded meaning. We introduce the DT-RNN model which uses dependency trees to embed sentences into a vector space in order to retrieve images that are described by those sentences. Unlike previous RNN-based models which use constituency trees, DT-RNNs naturally focus on the action and agents in a sentence. They are better able to abstract from the details of word order and syntactic expression. DT-RNNs outperform other recursive and recurrent neural networks, kernelized CCA and a bag-of-words baseline on the tasks of finding an image that fits a sentence description and vice versa. They also give more similar representations to sentences that describe the same image.},
  address   = {Cambridge, MA},
  doi       = {10.1162/tacl_a_00177},
  editor    = {Lin, Dekang and Collins, Michael and Lee, Lillian},
  file      = {:papers/Socher2014 - Grounded Compositional Semantics for Finding and Describing Images with Sentences.pdf:PDF},
  groups    = {Grounding, MLT Thesis},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/Q14-1017}
}

@incollection{Steels2009,
  author     = {Luc Steels and Martin Loetzsch},
  booktitle  = {Spatial Language and Dialogue},
  publisher  = {Oxford University Press},
  title      = {Perspective Alignment in Spatial Language},
  year       = {2009},
  editor     = {Kenny R. Coventry and Thora Tenbrink and John A. Bateman},
  pages      = {70--88},
  series     = {Explorations in language and space},
  volume     = {3},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/books/ox/09/SteelsL09.bib},
  doi        = {10.1093/acprof:oso/9780199554201.003.0006},
  file       = {:papers/Steels2009 - Perspective Alignment in Spatial Language.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {read},
  timestamp  = {Thu, 19 Nov 2020 09:11:25 +0100}
}

@mastersthesis{Storckenfeldt2018,
  author = {Storckenfeldt, Axel},
  school = {University of Gothenburg},
  title  = {Categorization of conversational games in free dialogue referring to spatial scenes},
  year   = {2018},
  month  = oct,
  type   = {candthesis},
  file   = {:papers/Storckenfeldt2018 - Categorization of Conversational Games in Free Dialogue Referring to Spatial Scenes.pdf:PDF},
  groups = {MLT Thesis}
}

@inproceedings{Toshniwal2021,
  author    = {Toshniwal, Shubham and Xia, Patrick and Wiseman, Sam and Livescu, Karen and Gimpel, Kevin},
  booktitle = {Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference},
  title     = {On Generalization in Coreference Resolution},
  year      = {2021},
  address   = {Punta Cana, Dominican Republic},
  editor    = {Ogrodniczuk, Maciej and Pradhan, Sameer and Poesio, Massimo and Grishina, Yulia and Ng, Vincent},
  month     = nov,
  pages     = {111--120},
  publisher = {Association for Computational Linguistics},
  abstract  = {While coreference resolution is defined independently of dataset domain, most models for performing coreference resolution do not transfer well to unseen domains. We consolidate a set of 8 coreference resolution datasets targeting different domains to evaluate the off-the-shelf performance of models. We then mix three datasets for training; even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities. We find that in a zero-shot setting, models trained on a single dataset transfer poorly while joint training yields improved overall performance, leading to better generalization in coreference resolution models. This work contributes a new benchmark for robust coreference resolution and multiple new state-of-the-art results.},
  doi       = {10.18653/v1/2021.crac-1.12},
  file      = {:papers/Toshniwal2021 - On Generalization in Coreference Resolution.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/2021.crac-1.12}
}

@article{Tsimpoukelli2021,
  author        = {Tsimpoukelli, Maria and Menick, Jacob and Cabi, Serkan and Eslami, S. M. Ali and Vinyals, Oriol and Hill, Felix},
  title         = {Multimodal Few-Shot Learning with Frozen Language Models},
  year          = {2021},
  month         = jun,
  abstract      = {When trained at sufficient scale, auto-regressive language models exhibit the notable ability to learn a new language task after being prompted with just a few examples. Here, we present a simple, yet effective, approach for transferring this few-shot learning ability to a multimodal setting (vision and language). Using aligned image and caption data, we train a vision encoder to represent each image as a sequence of continuous embeddings, such that a pre-trained, frozen language model prompted with this prefix generates the appropriate caption. The resulting system is a multimodal few-shot learner, with the surprising ability to learn a variety of new tasks when conditioned on examples, represented as a sequence of multiple interleaved image and text embeddings. We demonstrate that it can rapidly learn words for new objects and novel visual categories, do visual question-answering with only a handful of examples, and make use of outside knowledge, by measuring a single model on a variety of established and new benchmarks.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2106.13884},
  eprint        = {2106.13884},
  file          = {:papers/Tsimpoukelli2021 - Multimodal Few Shot Learning with Frozen Language Models.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv}
}

@inproceedings{Wang2021,
  author    = {Wang, Liming and Feng, Shengyu and Lin, Xudong and Li, Manling and Ji, Heng and Chang, Shih-Fu},
  booktitle = {Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference},
  title     = {Coreference by Appearance: Visually Grounded Event Coreference Resolution},
  year      = {2021},
  address   = {Punta Cana, Dominican Republic},
  editor    = {Ogrodniczuk, Maciej and Pradhan, Sameer and Poesio, Massimo and Grishina, Yulia and Ng, Vincent},
  month     = nov,
  pages     = {132--140},
  publisher = {Association for Computational Linguistics},
  abstract  = {Event coreference resolution is critical to understand events in the growing number of online news with multiple modalities including text, video, speech, etc. However, the events and entities depicting in different modalities may not be perfectly aligned and can be difficult to annotate, which makes the task especially challenging with little supervision available. To address the above issues, we propose a supervised model based on attention mechanism and an unsupervised model based on statistical machine translation, capable of learning the relative importance of modalities for event coreference resolution. Experiments on a video multimedia event dataset show that our multimodal models outperform text-only systems in event coreference resolution tasks. A careful analysis reveals that the performance gain of the multimodal model especially under unsupervised settings comes from better learning of visually salient events.},
  doi       = {10.18653/v1/2021.crac-1.14},
  file      = {:papers/Wang2021 - Coreference by Appearance_ Visually Grounded Event Coreference Resolution.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/2021.crac-1.14}
}

@inproceedings{Weidinger2022,
  author    = {Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and Biles, Courtney and Brown, Sasha and Kenton, Zac and Hawkins, Will and Stepleton, Tom and Birhane, Abeba and Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and Haas, Julia and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
  booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  title     = {Taxonomy of Risks Posed by Language Models},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {214–229},
  publisher = {Association for Computing Machinery},
  series    = {FAccT '22},
  abstract  = {Responsible innovation on large-scale Language Models (LMs) requires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxonomy of ethical and social risks associated with LMs. We identify twenty-one risks, drawing on expertise and literature from computer science, linguistics, and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination, Hate speech and Exclusion, II. Information Hazards, III. Misinformation Harms, IV. Malicious Uses, V. Human-Computer Interaction Harms, and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs, the causal mechanism leading to harm, evidence of the risk, and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies, and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.},
  doi       = {10.1145/3531146.3533088},
  file      = {:papers/Weidinger2022 - Taxonomy of Risks Posed by Language Models.pdf:PDF},
  groups    = {MLT Thesis},
  isbn      = {9781450393522},
  keywords  = {responsible AI, risk assessment, language models, responsible innovation, technology risks},
  location  = {Seoul, Republic of Korea},
  numpages  = {16}
}

@article{Williams1992,
  author     = {Ronald J. Williams},
  journal    = {Machine Learning},
  title      = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  year       = {1992},
  month      = {may},
  number     = {3-4},
  pages      = {229--256},
  volume     = {8},
  doi        = {10.1007/bf00992696},
  file       = {:papers/Williams1992 - Simple Statistical Gradient Following Algorithms for Connectionist Reinforcement Learning.pdf:PDF},
  groups     = {MLT Thesis},
  publisher  = {Springer Science and Business Media {LLC}},
  readstatus = {skimmed}
}

@article{Winograd1972,
  author   = {Terry Winograd},
  journal  = {Cognitive Psychology},
  title    = {Understanding natural language},
  year     = {1972},
  issn     = {0010-0285},
  number   = {1},
  pages    = {1-191},
  volume   = {3},
  abstract = {This paper describes a computer system for understanding English. The system answers questions, executes commands, and accepts information in an interactive English dialog. It is based on the belief that in modeling language understanding, we must deal in an integrated way with all of the aspects of language—syntax, semantics, and inference. The system contains a parser, a recognition grammar of English, programs for semantic analysis, and a general problem solving system. We assume that a computer cannot deal reasonably with language unless it can understand the subject it is discussing. Therefore, the program is given a detailed model of a particular domain. In addition, the system has a simple model of its own mentality. It can remember and discuss its plans and actions as well as carrying them out. It enters into a dialog with a person, responding to English sentences with actions and English replies, asking for clarification when its heuristic programs cannot understand a sentence through the use of syntactic, semantic, contextual, and physical knowledge. Knowledge in the system is represented in the form of procedures, rather than tables of rules or lists of patterns. By developing special procedural representations for syntax, semantics, and inference, we gain flexibility and power. Since each piece of knowledge can be a procedure, it can call directly on any other piece of knowledge in the system.},
  doi      = {https://doi.org/10.1016/0010-0285(72)90002-3},
  file     = {:papers/Winograd1972 - Understanding Natural Language.pdf:PDF},
  groups   = {Referring expressions, MLT Thesis, Grounding},
  url      = {https://www.sciencedirect.com/science/article/pii/0010028572900023}
}

@book{Wittgenstein1953,
  author    = {Wittgenstein, Ludwig},
  publisher = {Basil Blackwell},
  title     = {Philosophische Untersuchungen},
  year      = {1953},
  address   = {Oxford},
  file      = {:papers/Wittgenstein1953 - Philosophische Untersuchungen.pdf:PDF},
  groups    = {MLT Thesis},
  language  = {German}
}

@inproceedings{Xiong2016,
  author    = {Caiming Xiong and Stephen Merity and Richard Socher},
  booktitle = {International Conference on Machine Learning},
  title     = {Dynamic Memory Networks for Visual and Textual Question Answering},
  year      = {2016},
  file      = {:papers/Xiong2016 - Dynamic Memory Networks for Visual and Textual Question Answering.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis},
  url       = {https://api.semanticscholar.org/CorpusID:14294589}
}

@inproceedings{Xu2016,
  author    = {Xu, Huijuan and Saenko, Kate},
  booktitle = {Computer Vision -- ECCV 2016},
  title     = {Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering},
  year      = {2016},
  address   = {Cham},
  editor    = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  pages     = {451--466},
  publisher = {Springer International Publishing},
  abstract  = {We address the problem of Visual Question Answering (VQA), which requires joint image and language understanding to answer a question about a given photograph. Recent approaches have applied deep image captioning methods based on convolutional-recurrent networks to this problem, but have failed to model spatial inference. To remedy this, we propose a model we call the Spatial Memory Network and apply it to the VQA task. Memory networks are recurrent neural networks with an explicit attention mechanism that selects certain parts of the information stored in memory. Our Spatial Memory Network stores neuron activations from different spatial regions of the image in its memory, and uses attention to choose regions relevant for computing the answer. We propose a novel question-guided spatial attention architecture that looks for regions relevant to either individual words or the entire question, repeating the process over multiple recurrent steps, or ``hops''. To better understand the inference process learned by the network, we design synthetic questions that specifically require spatial inference and visualize the network's attention. We evaluate our model on two available visual question answering datasets and obtain improved results.},
  file      = {:papers/Xu2016 - Ask, Attend and Answer_ Exploring Question Guided Spatial Attention for Visual Question Answering.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis},
  isbn      = {978-3-319-46478-7}
}

@inproceedings{Yosinski2014,
  author    = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
  title     = {How Transferable Are Features in Deep Neural Networks?},
  year      = {2014},
  address   = {Cambridge, MA, USA},
  pages     = {3320-3328},
  publisher = {MIT Press},
  series    = {NIPS'14},
  abstract  = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
  file      = {:papers/Yosinski2014 - How Transferable Are Features in Deep Neural Networks_.pdf:PDF},
  groups    = {MLT Thesis},
  location  = {Montreal, Canada},
  numpages  = {9}
}

@inproceedings{Yu2019,
  author    = {Yu, Xintong and Zhang, Hongming and Song, Yangqiu and Song, Yan and Zhang, Changshui},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  title     = {What You See is What You Get: Visual Pronoun Coreference Resolution in Dialogues},
  year      = {2019},
  address   = {Hong Kong, China},
  editor    = {Inui, Kentaro and Jiang, Jing and Ng, Vincent and Wan, Xiaojun},
  month     = nov,
  pages     = {5123--5132},
  publisher = {Association for Computational Linguistics},
  abstract  = {Grounding a pronoun to a visual object it refers to requires complex reasoning from various information sources, especially in conversational scenarios. For example, when people in a conversation talk about something all speakers can see, they often directly use pronouns (e.g., it) to refer to it without previous introduction. This fact brings a huge challenge for modern natural language understanding systems, particularly conventional context-based pronoun coreference models. To tackle this challenge, in this paper, we formally define the task of visual-aware pronoun coreference resolution (PCR) and introduce VisPro, a large-scale dialogue PCR dataset, to investigate whether and how the visual information can help resolve pronouns in dialogues. We then propose a novel visual-aware PCR model, VisCoref, for this task and conduct comprehensive experiments and case studies on our dataset. Results demonstrate the importance of the visual information in this PCR case and show the effectiveness of the proposed model.},
  doi       = {10.18653/v1/D19-1516},
  file      = {:papers/Yu2019 - What You See Is What You Get_ Visual Pronoun Coreference Resolution in Dialogues.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/D19-1516}
}

@inproceedings{Zarriess2019,
  author    = {Zarrie{\ss}, Sina and Schlangen, David},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  title     = {Know What You Don{'}t Know: Modeling a Pragmatic Speaker that Refers to Objects of Unknown Categories},
  year      = {2019},
  address   = {Florence, Italy},
  editor    = {Korhonen, Anna and Traum, David and M{\`a}rquez, Llu{\'\i}s},
  month     = jul,
  pages     = {654--659},
  publisher = {Association for Computational Linguistics},
  abstract  = {Zero-shot learning in Language {\&} Vision is the task of correctly labelling (or naming) objects of novel categories. Another strand of work in L{\&}V aims at pragmatically informative rather than {``}correct{''} object descriptions, e.g. in reference games. We combine these lines of research and model zero-shot reference games, where a speaker needs to successfully refer to a novel object in an image. Inspired by models of {``}rational speech acts{''}, we extend a neural generator to become a pragmatic speaker reasoning about uncertain object categories. As a result of this reasoning, the generator produces fewer nouns and names of distractor categories as compared to a literal speaker. We show that this conversational strategy for dealing with novel objects often improves communicative success, in terms of resolution accuracy of an automatic listener.},
  doi       = {10.18653/v1/P19-1063},
  file      = {:papers/Zarriess2019 - Know What You Don't Know_ Modeling a Pragmatic Speaker That Refers to Objects of Unknown Categories.pdf:PDF},
  groups    = {MLT Thesis, Grounding, Referring expressions},
  url       = {https://aclanthology.org/P19-1063}
}

@article{Zaslavsky2018,
  author    = {Noga Zaslavsky and Charles Kemp and Terry Regier and Naftali Tishby},
  journal   = {Proceedings of the National Academy of Sciences},
  title     = {Efficient compression in color naming and its evolution},
  year      = {2018},
  month     = {jul},
  number    = {31},
  pages     = {7937--7942},
  volume    = {115},
  doi       = {10.1073/pnas.1800521115},
  file      = {:papers/Zaslavsky2018 - Efficient Compression in Color Naming and Its Evolution.pdf:PDF},
  groups    = {AI: Cognitive System, MLT Thesis,},
  publisher = {Proceedings of the National Academy of Sciences},
  url       = {http://lclab.berkeley.edu/papers/zaslavsky-et-al-IB-
               2018.pdf}
}

@inproceedings{Zhang2021,
  author    = {Zhang, Hongming and Zhao, Xinran and Song, Yangqiu},
  booktitle = {Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference},
  title     = {A Brief Survey and Comparative Study of Recent Development of Pronoun Coreference Resolution in {E}nglish},
  year      = {2021},
  address   = {Punta Cana, Dominican Republic},
  editor    = {Ogrodniczuk, Maciej and Pradhan, Sameer and Poesio, Massimo and Grishina, Yulia and Ng, Vincent},
  month     = nov,
  pages     = {1--11},
  publisher = {Association for Computational Linguistics},
  abstract  = {Pronoun Coreference Resolution (PCR) is the task of resolving pronominal expressions to all mentions they refer to. Compared with the general coreference resolution task, the main challenge of PCR is the coreference relation prediction rather than the mention detection. As one important natural language understanding (NLU) component, pronoun resolution is crucial for many downstream tasks and still challenging for existing models, which motivates us to survey existing approaches and think about how to do better. In this survey, we first introduce representative datasets and models for the ordinary pronoun coreference resolution task. Then we focus on recent progress on hard pronoun coreference resolution problems (e.g., Winograd Schema Challenge) to analyze how well current models can understand commonsense. We conduct extensive experiments to show that even though current models are achieving good performance on the standard evaluation set, they are still not ready to be used in real applications (e.g., all SOTA models struggle on correctly resolving pronouns to infrequent objects). All experiment codes will be available upon acceptance.},
  doi       = {10.18653/v1/2021.crac-1.1},
  file      = {:papers/Zhang2021 - A Brief Survey and Comparative Study of Recent Development of Pronoun Coreference Resolution in English.pdf:PDF},
  groups    = {RE resolution, Referring expressions, MLT Thesis,},
  url       = {https://aclanthology.org/2021.crac-1.1}
}
